#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Claude Code å†å²å¯¹è¯ç®¡ç†å·¥å…· - GUIç‰ˆæœ¬
ç”¨äºç®¡ç†å’Œæµè§ˆ Claude Code projects ç›®å½•ä¸‹çš„å†å²å¯¹è¯
"""

import os
import json
import sys
import re
import tkinter as tk
from tkinter import ttk, messagebox, filedialog
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import threading
import concurrent.futures
from functools import lru_cache
import time


class TokenCalculator:
    """Tokenè®¡ç®—å™¨ - æ”¯æŒç²¾ç¡®è®¡ç®—å’Œæ™ºèƒ½ä¼°ç®—"""

    def __init__(self):
        self.encoder = None
        self.precise_mode = False
        self._init_encoder()

        # ç¼“å­˜ç»Ÿè®¡
        self.cache_hits = 0
        self.cache_misses = 0

    @lru_cache(maxsize=1024)
    def count_tokens_cached(self, text: str) -> int:
        """å¸¦ç¼“å­˜çš„tokenè®¡ç®—"""
        return self.count_tokens(text)

    def _init_encoder(self):
        """åˆå§‹åŒ–tokenç¼–ç å™¨"""
        try:
            import tiktoken
            self.encoder = tiktoken.get_encoding("o200k_base")  # Claudeä½¿ç”¨çš„ç¼–ç å™¨
            self.precise_mode = True
            print("âœ… å·²åŠ è½½tiktokenï¼Œä½¿ç”¨ç²¾ç¡®tokenè®¡ç®—æ¨¡å¼")
        except ImportError:
            self.encoder = None
            self.precise_mode = False
            print("âš ï¸  æœªå®‰è£…tiktokenï¼Œä½¿ç”¨æ™ºèƒ½ä¼°ç®—æ¨¡å¼")
        except Exception as e:
            self.encoder = None
            self.precise_mode = False
            print(f"âš ï¸  tiktokenåˆå§‹åŒ–å¤±è´¥: {e}ï¼Œä½¿ç”¨æ™ºèƒ½ä¼°ç®—æ¨¡å¼")

    def count_tokens(self, text: str) -> int:
        """è®¡ç®—æ–‡æœ¬çš„tokenæ•°é‡"""
        if not text or not text.strip():
            return 0

        text = text.strip()

        # ç²¾ç¡®æ¨¡å¼
        if self.precise_mode and self.encoder:
            try:
                return len(self.encoder.encode(text))
            except Exception as e:
                print(f"Tokenè®¡ç®—é”™è¯¯ï¼Œåˆ‡æ¢åˆ°ä¼°ç®—æ¨¡å¼: {e}")
                return self._estimate_tokens(text)

        # ä¼°ç®—æ¨¡å¼
        return self._estimate_tokens(text)

    def _estimate_tokens(self, text: str) -> int:
        """æ™ºèƒ½tokenä¼°ç®—ç®—æ³•"""
        if not text:
            return 0

        # ä¸­æ–‡å­—ç¬¦ç»Ÿè®¡
        chinese_chars = len(re.findall(r"[\u4e00-\u9fff]", text))

        # è‹±æ–‡å­—ç¬¦ç»Ÿè®¡
        english_chars = len(re.findall(r"[a-zA-Z]", text))

        # æ•°å­—ç»Ÿè®¡
        digit_chars = len(re.findall(r"[0-9]", text))

        # æ ‡ç‚¹ç¬¦å·å’Œç©ºæ ¼
        space_chars = len(re.findall(r"\s", text))
        punct_chars = len(re.findall(r"[^\w\s\u4e00-\u9fff]", text))

        # Tokenä¼°ç®—è§„åˆ™ï¼ˆåŸºäºClaudeçš„tokenizationç‰¹ç‚¹ï¼‰
        # ä¸­æ–‡å­—ç¬¦ï¼šé€šå¸¸1-2ä¸ªå­—ç¬¦=1token
        chinese_tokens = chinese_chars * 1.8

        # è‹±æ–‡å•è¯ï¼šå¹³å‡4ä¸ªå­—ç¬¦=1token
        english_tokens = english_chars / 4.0

        # æ•°å­—ï¼šé€šå¸¸1-3ä¸ªæ•°å­—=1token
        digit_tokens = digit_chars / 2.0

        # ç©ºæ ¼å’Œæ ‡ç‚¹ï¼šé€šå¸¸å¤šä¸ª=1token
        other_tokens = (space_chars + punct_chars) / 5.0

        total_tokens = chinese_tokens + english_tokens + digit_tokens + other_tokens

        return max(1, int(total_tokens))

    def count_message_tokens(self, message_data: Dict) -> int:
        """è®¡ç®—å•ä¸ªæ¶ˆæ¯çš„tokenæ•°é‡ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        # ä¸ºæ¶ˆæ¯åˆ›å»ºç¼“å­˜é”®ï¼ˆåŸºäºæ¶ˆæ¯å†…å®¹çš„hashï¼‰
        cache_key = self._create_message_cache_key(message_data)

        if hasattr(self, '_message_token_cache'):
            if cache_key in self._message_token_cache:
                self.cache_hits += 1
                return self._message_token_cache[cache_key]
        else:
            self._message_token_cache = {}

        self.cache_misses += 1
        total_tokens = self._calculate_message_tokens(message_data)

        # ç¼“å­˜ç»“æœ
        self._message_token_cache[cache_key] = total_tokens

        # é™åˆ¶ç¼“å­˜å¤§å°
        if len(self._message_token_cache) > 500:
            # åˆ é™¤ä¸€äº›æ—§ç¼“å­˜
            keys_to_remove = list(self._message_token_cache.keys())[:100]
            for key in keys_to_remove:
                del self._message_token_cache[key]

        return total_tokens

    def _create_message_cache_key(self, message_data: Dict) -> str:
        """ä¸ºæ¶ˆæ¯åˆ›å»ºç¼“å­˜é”®"""
        try:
            # åˆ›å»ºåŸºäºå†…å®¹çš„hash
            import hashlib
            content_str = json.dumps(message_data, sort_keys=True, ensure_ascii=False)
            return hashlib.md5(content_str.encode('utf-8')).hexdigest()[:16]
        except:
            # å¦‚æœåºåˆ—åŒ–å¤±è´¥ï¼Œä½¿ç”¨ç±»å‹å’Œæ—¶é—´æˆ³ä½œä¸ºé”®
            msg_type = message_data.get('type', 'unknown')
            timestamp = message_data.get('timestamp', '')
            return f"{msg_type}_{timestamp}"

    def _calculate_message_tokens(self, message_data: Dict) -> int:
        """å®é™…è®¡ç®—æ¶ˆæ¯tokenæ•°é‡"""
        total_tokens = 0

        msg_type = message_data.get('type', '')

        if msg_type == 'summary':
            # æ‘˜è¦æ¶ˆæ¯
            summary = message_data.get('summary', '')
            total_tokens += self.count_tokens_cached(summary)

        elif msg_type in ['user', 'assistant']:
            # ç”¨æˆ·å’ŒåŠ©æ‰‹æ¶ˆæ¯
            message = message_data.get('message', {})
            content = message.get('content', '')

            if isinstance(content, str):
                total_tokens += self.count_tokens_cached(content)
            elif isinstance(content, list):
                for item in content:
                    if item.get('type') == 'text':
                        total_tokens += self.count_tokens_cached(item.get('text', ''))
                    elif item.get('type') == 'image':
                        # å›¾ç‰‡æ¶ˆæ¯é€šå¸¸æœ‰å›ºå®šçš„tokenå¼€é”€
                        total_tokens += 85  # Claudeçš„å›¾ç‰‡tokenä¼°ç®—å€¼

        # æ¶ˆæ¯ç»“æ„å¼€é”€ï¼ˆJSONç»“æ„ã€æ—¶é—´æˆ³ç­‰ï¼‰
        total_tokens += 10  # åŸºç¡€ç»“æ„å¼€é”€

        return total_tokens

    def analyze_conversation_tokens(self, conversation_data: List[Dict]) -> Dict:
        """åˆ†ææ•´ä¸ªå¯¹è¯çš„tokenä½¿ç”¨æƒ…å†µ"""
        if not conversation_data:
            return {
                'total_tokens': 0,
                'user_tokens': 0,
                'assistant_tokens': 0,
                'summary_tokens': 0,
                'message_count': 0,
                'avg_tokens_per_message': 0
            }

        total_tokens = 0
        user_tokens = 0
        assistant_tokens = 0
        summary_tokens = 0
        message_count = 0

        for line_num, data in conversation_data:
            msg_type = data.get('type', '')
            msg_tokens = self.count_message_tokens(data)

            total_tokens += msg_tokens
            message_count += 1

            if msg_type == 'user':
                user_tokens += msg_tokens
            elif msg_type == 'assistant':
                assistant_tokens += msg_tokens
            elif msg_type == 'summary':
                summary_tokens += msg_tokens

        avg_tokens = total_tokens / message_count if message_count > 0 else 0

        return {
            'total_tokens': total_tokens,
            'user_tokens': user_tokens,
            'assistant_tokens': assistant_tokens,
            'summary_tokens': summary_tokens,
            'message_count': message_count,
            'avg_tokens_per_message': round(avg_tokens, 1)
        }

    def format_tokens(self, token_count: int) -> str:
        """æ ¼å¼åŒ–tokenæ•°é‡æ˜¾ç¤º"""
        if token_count < 1000:
            return f"{token_count:,}"
        elif token_count < 1000000:
            return f"{token_count/1000:.1f}K"
        else:
            return f"{token_count/1000000:.1f}M"

    def get_token_cost_estimate(self, token_count: int, model: str = "claude-3-5-sonnet") -> Dict:
        """ä¼°ç®—tokenæˆæœ¬ï¼ˆåŸºäºClaudeå®šä»·ï¼‰"""
        # å®šä»·æ•°æ®ï¼ˆæ¯1M tokensçš„ç¾å…ƒä»·æ ¼ï¼‰
        pricing = {
            "claude-3-5-sonnet": {"input": 3.0, "output": 15.0},
            "claude-3-5-haiku": {"input": 0.25, "output": 1.25},
            "claude-3-opus": {"input": 15.0, "output": 75.0},
        }

        if model not in pricing:
            model = "claude-3-5-sonnet"

        input_cost = (token_count / 1000000) * pricing[model]["input"]
        output_cost = (token_count / 1000000) * pricing[model]["output"]

        return {
            "model": model,
            "input_cost": round(input_cost, 4),
            "output_cost": round(output_cost, 4),
            "total_cost": round(input_cost + output_cost, 4)
        }


class ConversationViewer:
    """å¯¹è¯å†…å®¹æŸ¥çœ‹å™¨ - é›†æˆåˆ°ä¸»ç•Œé¢"""

    def __init__(self, parent):
        self.parent = parent
        self.current_data = []
        self.current_conversation_info = None

    def show_conversation(self, file_path: str, conversation_info: Dict):
        """æ˜¾ç¤ºå¯¹è¯å†…å®¹åˆ°ä¸»ç•Œé¢ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰"""
        self.current_conversation_info = conversation_info
        self.current_data = []

        # å…ˆæ˜¾ç¤ºåŠ è½½çŠ¶æ€
        self.parent.conversation_info_label.config(
            text=f"{conversation_info['file_name']} (æ­£åœ¨åŠ è½½...)"
        )
        self.parent.message_listbox.delete(0, tk.END)
        self.parent.message_listbox.insert(tk.END, "ğŸ”„ æ­£åœ¨åŠ è½½å¯¹è¯å†…å®¹...")
        self.parent.content_text.delete(1.0, tk.END)
        self.parent.content_text.insert(tk.END, "æ­£åœ¨åŠ è½½å¯¹è¯å†…å®¹ï¼Œè¯·ç¨å€™...")

        # åœ¨åå°çº¿ç¨‹ä¸­åŠ è½½å¯¹è¯å†…å®¹
        threading.Thread(
            target=self._load_conversation_content,
            args=(file_path, conversation_info),
            daemon=True
        ).start()

    def _load_conversation_content(self, file_path: str, conversation_info: Dict):
        """åå°åŠ è½½å¯¹è¯å†…å®¹"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_path):
                raise FileNotFoundError(f"å¯¹è¯æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(file_path)
            if file_size == 0:
                raise ValueError(f"å¯¹è¯æ–‡ä»¶ä¸ºç©º: {file_path}")

            # å»¶è¿ŸåŠ è½½ï¼šå…ˆè¯»å–å‰å‡ æ¡æ¶ˆæ¯å¿«é€Ÿæ˜¾ç¤º
            quick_data = []
            full_data = []

            with open(file_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    if not line.strip():
                        continue

                    try:
                        data = json.loads(line)

                        # æ·»åŠ åˆ°å®Œæ•´æ•°æ®
                        full_data.append((line_num, data))

                        # å‰10æ¡æ¶ˆæ¯ç”¨äºå¿«é€Ÿæ˜¾ç¤º
                        if len(quick_data) < 10:
                            quick_data.append((line_num, data))

                        # æ¯20æ¡æ¶ˆæ¯æ›´æ–°ä¸€æ¬¡UIï¼ˆå¯¹äºå¤§æ–‡ä»¶ï¼‰
                        elif len(full_data) % 20 == 0:
                            self.parent.root.after(0, lambda d=full_data.copy(): self._update_loading_progress(d))

                    except json.JSONDecodeError as e:
                        print(f"è­¦å‘Š: è·³è¿‡æ— æ•ˆçš„JSONè¡Œ {line_num}: {e}")
                        continue
                    except Exception as e:
                        print(f"è­¦å‘Š: å¤„ç†è¡Œ {line_num} æ—¶å‡ºé”™: {e}")
                        continue

            # è®¾ç½®å®Œæ•´æ•°æ®
            self.current_data = full_data

            # æ›´æ–°UI
            self.parent.root.after(0, lambda: self._finish_loading(conversation_info, full_data))

        except FileNotFoundError as e:
            self.parent.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"æ–‡ä»¶ä¸å­˜åœ¨: {e}"))
        except PermissionError as e:
            self.parent.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"æ²¡æœ‰æ–‡ä»¶è¯»å–æƒé™: {e}"))
        except UnicodeDecodeError as e:
            self.parent.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"æ–‡ä»¶ç¼–ç é”™è¯¯: {e}"))
        except ValueError as e:
            self.parent.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}"))
        except Exception as e:
            self.parent.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"è¯»å–å¯¹è¯æ–‡ä»¶å¤±è´¥: {e}"))
            # è®°å½•è¯¦ç»†é”™è¯¯ç”¨äºè°ƒè¯•
            print(f"è¯»å–å¯¹è¯æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", file=sys.stderr)

    def _update_loading_progress(self, current_data):
        """æ›´æ–°åŠ è½½è¿›åº¦"""
        count = len(current_data)
        self.parent.conversation_info_label.config(
            text=f"{self.current_conversation_info['file_name']} (å·²åŠ è½½ {count} æ¡æ¶ˆæ¯...)"
        )

    def _finish_loading(self, conversation_info: Dict, full_data: List[Tuple]):
        """å®ŒæˆåŠ è½½å¹¶æ›´æ–°UI"""
        # æ›´æ–°çˆ¶ç•Œé¢çš„å¯¹è¯å†…å®¹åŒºåŸŸ
        self.parent.update_conversation_content(conversation_info, full_data)

    def populate_message_list(self, message_listbox):
        """å¡«å……æ¶ˆæ¯åˆ—è¡¨åˆ°ä¸»ç•Œé¢"""
        message_listbox.delete(0, tk.END)

        # æ€§èƒ½ä¼˜åŒ–ï¼šå¦‚æœæ¶ˆæ¯æ•°é‡å¾ˆå¤§ï¼Œæ˜¾ç¤ºè­¦å‘Šå¹¶é™åˆ¶æ˜¾ç¤º
        max_display_items = 1000
        data_to_display = self.current_data[:max_display_items]

        if len(self.current_data) > max_display_items:
            # æ˜¾ç¤ºå¤§é‡æ¶ˆæ¯çš„æç¤º
            message_listbox.insert(tk.END, f"ğŸ“Š å…± {len(self.current_data)} æ¡æ¶ˆæ¯ï¼Œæ˜¾ç¤ºå‰ {max_display_items} æ¡")

        for line_num, data in data_to_display:
            msg_type = data.get('type', 'unknown')
            timestamp = data.get('timestamp', '')

            # æ ¼å¼åŒ–æ—¶é—´æˆ³
            if timestamp:
                try:
                    dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                    time_str = dt.strftime("%H:%M:%S")
                except:
                    time_str = timestamp[:8] if len(timestamp) >= 8 else timestamp
            else:
                time_str = ""

            # è·å–æ¶ˆæ¯é¢„è§ˆ
            preview = ""
            if msg_type == 'summary':
                preview = f"ğŸ“ æ‘˜è¦: {data.get('summary', '')[:50]}..."
            elif msg_type in ['user', 'assistant']:
                content = data.get('message', {}).get('content', '')
                if isinstance(content, str):
                    preview = content[:50].replace('\n', ' ') + "..."
                elif isinstance(content, list) and content:
                    text = content[0].get('text', '')
                    preview = text[:50].replace('\n', ' ') + "..."

            # ç¡®å®šè§’è‰²å›¾æ ‡
            if msg_type == 'user':
                icon = "ğŸ‘¤"
            elif msg_type == 'assistant':
                icon = "ğŸ¤–"
            elif msg_type == 'summary':
                icon = "ğŸ“"
            else:
                icon = "ğŸ“„"

            # åˆ—è¡¨é¡¹æ ¼å¼
            list_item = f"{icon} [{time_str}] {preview}"
            message_listbox.insert(tk.END, list_item)

    def display_message_content(self, content_text, status_label, index):
        """æ˜¾ç¤ºé€‰ä¸­æ¶ˆæ¯çš„å†…å®¹"""
        if index >= len(self.current_data):
            return

        line_num, data = self.current_data[index]

        # æ¸…ç©ºå¹¶æ˜¾ç¤ºæ¶ˆæ¯å†…å®¹
        content_text.delete(1.0, tk.END)

        msg_type = data.get('type', 'unknown')
        timestamp = data.get('timestamp', '')

        # æ¶ˆæ¯å¤´éƒ¨
        header = f"ç±»å‹: {msg_type}\n"
        if timestamp:
            try:
                dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                header += f"æ—¶é—´: {dt.strftime('%Y-%m-%d %H:%M:%S')}\n"
            except:
                header += f"æ—¶é—´: {timestamp}\n"

        header += f"è¡Œå·: {line_num}\n"
        header += "-" * 50 + "\n\n"

        content_text.insert(tk.END, header)

        # æ¶ˆæ¯å†…å®¹
        if msg_type == 'summary':
            content = data.get('summary', '')
            content_text.insert(tk.END, f"æ‘˜è¦å†…å®¹:\n{content}")
        elif msg_type in ['user', 'assistant']:
            message_data = data.get('message', {})
            content = message_data.get('content', '')

            if isinstance(content, str):
                content_text.insert(tk.END, content)
            elif isinstance(content, list):
                for item in content:
                    if item.get('type') == 'text':
                        content_text.insert(tk.END, item.get('text', ''))
                    elif item.get('type') == 'image':
                        content_text.insert(tk.END, f"[å›¾ç‰‡: {item.get('source', '')}]\n")
                    else:
                        content_text.insert(tk.END, f"[{item.get('type', 'unknown')}: {item}]\n")
        else:
            content_text.insert(tk.END, f"å…¶ä»–æ•°æ®:\n{json.dumps(data, ensure_ascii=False, indent=2)}")

        status_label.config(text=f"æ˜¾ç¤ºæ¶ˆæ¯ {index + 1}/{len(self.current_data)}")

    def export_current_conversation(self, format_type: str = 'markdown'):
        """å¯¼å‡ºå½“å‰å¯¹è¯"""
        if not self.current_data:
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰æ•°æ®å¯å¯¼å‡º")
            return

        if format_type == 'markdown':
            self._export_markdown()
        elif format_type == 'json':
            self._export_json()

    def _export_markdown(self):
        """å¯¼å‡ºä¸ºMarkdownæ ¼å¼"""
        filename = filedialog.asksaveasfilename(
            defaultextension=".md",
            initialfile=f"{self.current_conversation_info['file_name'].replace('.jsonl', '.md')}",
            filetypes=[("Markdownæ–‡ä»¶", "*.md"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )

        if not filename:
            return

        try:
            # è®¡ç®—tokenç»Ÿè®¡
            token_analysis = self.parent.token_calculator.analyze_conversation_tokens(self.current_data)
            cost_estimate = self.parent.token_calculator.get_token_cost_estimate(token_analysis['total_tokens'])

            with open(filename, 'w', encoding='utf-8') as f:
                f.write("# å¯¹è¯å¯¼å‡º\n\n")

                # å†™å…¥tokenç»Ÿè®¡ä¿¡æ¯
                f.write("## ğŸ“Š Tokenç»Ÿè®¡æŠ¥å‘Š\n\n")
                f.write(f"- **æ€»Tokenæ•°**: {self.parent.token_calculator.format_tokens(token_analysis['total_tokens'])}\n")
                f.write(f"- **ç”¨æˆ·Token**: {self.parent.token_calculator.format_tokens(token_analysis['user_tokens'])}\n")
                f.write(f"- **åŠ©æ‰‹Token**: {self.parent.token_calculator.format_tokens(token_analysis['assistant_tokens'])}\n")
                f.write(f"- **æ‘˜è¦Token**: {self.parent.token_calculator.format_tokens(token_analysis['summary_tokens'])}\n")
                f.write(f"- **æ¶ˆæ¯æ•°é‡**: {token_analysis['message_count']}\n")
                f.write(f"- **å¹³å‡Token/æ¶ˆæ¯**: {token_analysis['avg_tokens_per_message']}\n\n")

                f.write("### ğŸ’° æˆæœ¬ä¼°ç®—\n\n")
                f.write(f"- **æ¨¡å‹**: {cost_estimate['model']}\n")
                f.write(f"- **è¾“å…¥æˆæœ¬**: ${cost_estimate['input_cost']:.4f}\n")
                f.write(f"- **è¾“å‡ºæˆæœ¬**: ${cost_estimate['output_cost']:.4f}\n")
                f.write(f"- **æ€»æˆæœ¬**: ${cost_estimate['total_cost']:.4f}\n\n")

                f.write("---\n\n")

                # å†™å…¥å¯¹è¯å†…å®¹
                message_num = 1
                for line_num, data in self.current_data:
                    msg_type = data.get('type', 'unknown')
                    timestamp = data.get('timestamp', '')

                    if timestamp:
                        try:
                            dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                            time_str = f" ({dt.strftime('%Y-%m-%d %H:%M:%S')})"
                        except:
                            time_str = f" ({timestamp})"
                    else:
                        time_str = ""

                    # è®¡ç®—å½“å‰æ¶ˆæ¯çš„tokenæ•°
                    msg_tokens = self.parent.token_calculator.count_message_tokens(data)

                    if msg_type == 'user':
                        f.write(f"## ğŸ‘¤ ç”¨æˆ· {message_num}{time_str} ({self.parent.token_calculator.format_tokens(msg_tokens)} tokens)\n\n")
                        message_num += 1
                    elif msg_type == 'assistant':
                        f.write(f"## ğŸ¤– åŠ©æ‰‹ {message_num}{time_str} ({self.parent.token_calculator.format_tokens(msg_tokens)} tokens)\n\n")
                        message_num += 1
                    elif msg_type == 'summary':
                        f.write(f"## ğŸ“ æ‘˜è¦{time_str} ({self.parent.token_calculator.format_tokens(msg_tokens)} tokens)\n\n")
                    else:
                        f.write(f"## ğŸ“„ {msg_type}{time_str} ({self.parent.token_calculator.format_tokens(msg_tokens)} tokens)\n\n")

                    # å†™å…¥å†…å®¹
                    if msg_type == 'summary':
                        f.write(f"{data.get('summary', '')}\n\n")
                    elif msg_type in ['user', 'assistant']:
                        content = data.get('message', {}).get('content', '')
                        if isinstance(content, str):
                            f.write(f"{content}\n\n")
                        elif isinstance(content, list):
                            for item in content:
                                if item.get('type') == 'text':
                                    f.write(f"{item.get('text', '')}")
                                elif item.get('type') == 'image':
                                    f.write(f"[å›¾ç‰‡: {item.get('source', '')}]\n")
                    else:
                        f.write(f"```json\n{json.dumps(data, ensure_ascii=False, indent=2)}\n```\n\n")

                    f.write("---\n\n")

            messagebox.showinfo("æˆåŠŸ", f"å·²å¯¼å‡ºåˆ°: {filename}")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºå¤±è´¥: {e}")

    def _export_json(self):
        """å¯¼å‡ºä¸ºJSONæ ¼å¼"""
        filename = filedialog.asksaveasfilename(
            defaultextension=".json",
            initialfile=f"{self.current_conversation_info['file_name'].replace('.jsonl', '.json')}",
            filetypes=[("JSONæ–‡ä»¶", "*.json"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )

        if not filename:
            return

        try:
            # è®¡ç®—tokenç»Ÿè®¡
            token_analysis = self.parent.token_calculator.analyze_conversation_tokens(self.current_data)
            cost_estimate = self.parent.token_calculator.get_token_cost_estimate(token_analysis['total_tokens'])

            # å‡†å¤‡å¯¼å‡ºæ•°æ®
            export_data = {
                "metadata": {
                    "file_name": self.current_conversation_info['file_name'],
                    "export_time": datetime.now().isoformat(),
                    "total_messages": len(self.current_data),
                    "token_analysis": token_analysis,
                    "cost_estimate": cost_estimate,
                    "calculator_mode": "ç²¾ç¡®æ¨¡å¼" if self.parent.token_calculator.precise_mode else "ä¼°ç®—æ¨¡å¼"
                },
                "messages": []
            }

            # ä¸ºæ¯ä¸ªæ¶ˆæ¯æ·»åŠ tokenä¿¡æ¯
            for line_num, data in self.current_data:
                msg_data = data.copy()
                msg_data["line_number"] = line_num
                msg_data["token_count"] = self.parent.token_calculator.count_message_tokens(data)
                export_data["messages"].append(msg_data)

            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)

            messagebox.showinfo("æˆåŠŸ", f"å·²å¯¼å‡ºåˆ°: {filename}")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºå¤±è´¥: {e}")


class ClaudeHistoryGUI:
    """Claude Code å†å²å¯¹è¯ç®¡ç†å™¨ - GUIç‰ˆæœ¬"""

    def __init__(self):
        self.root = tk.Tk()
        self.root.title("Claude Code å†å²å¯¹è¯ç®¡ç†å™¨")
        self.root.geometry("1400x800")

        # è®¾ç½®æ ·å¼
        self.style = ttk.Style()
        self.style.theme_use('clam')

        # åˆå§‹åŒ–æ•°æ®
        self.projects_path = Path(os.path.expanduser("~/.claude/projects"))
        if os.name == 'nt':
            self.projects_path = Path(os.path.normpath(str(self.projects_path)))

        self.projects_data = {}
        self.current_project = None
        self.current_conversations = []
        self.current_conversation = None
        self.current_messages = []

        # æ’åºç›¸å…³
        self.sort_column = None
        self.sort_reverse = False  # False: å‡åº, True: é™åº
        self._sorting_in_progress = False  # é˜²æ­¢é‡å¤è§¦å‘æ’åº
        self._sort_block_timer = None  # æ’åºé˜»å¡å®šæ—¶å™¨

        # åˆ†é¡µç›¸å…³
        self.page_size = 50  # æ¯é¡µæ˜¾ç¤º50ä¸ªå¯¹è¯
        self.current_page = 1
        self.total_pages = 1
        self.filtered_conversations = []  # å½“å‰ç­›é€‰åçš„å¯¹è¯åˆ—è¡¨

        # åˆ›å»ºTokenè®¡ç®—å™¨
        self.token_calculator = TokenCalculator()

        # æœç´¢ç¼“å­˜å’Œç´¢å¼•
        self._search_cache = {}
        self._search_index = {}  # ç®€å•çš„æœç´¢ç´¢å¼•
        self._search_cache_max_size = 50

        # æ–‡ä»¶åˆ†æç¼“å­˜
        self._file_analysis_cache = {}
        self._file_cache_max_size = 100

        # åˆ›å»ºç»„ä»¶
        self.conversation_viewer = ConversationViewer(self)

        # åˆ›å»ºç•Œé¢
        self._create_widgets()

        # è®¾ç½®çª—å£å…³é—­äº‹ä»¶
        self.root.protocol("WM_DELETE_WINDOW", self._on_closing)

        # ç»‘å®šé”®ç›˜å¿«æ·é”®
        self._setup_keyboard_shortcuts()

        # åŠ è½½æ•°æ®
        self._load_projects()

    def _create_widgets(self):
        """åˆ›å»ºç•Œé¢ç»„ä»¶"""
        # åˆ›å»ºèœå•æ 
        menubar = tk.Menu(self.root)
        self.root.config(menu=menubar)

        # æ–‡ä»¶èœå•
        file_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="æ–‡ä»¶", menu=file_menu)
        file_menu.add_command(label="åˆ·æ–°", command=self._load_projects)
        file_menu.add_separator()
        file_menu.add_command(label="é€€å‡º", command=self.root.quit)

        # å·¥å…·èœå•
        tools_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="å·¥å…·", menu=tools_menu)
        tools_menu.add_command(label="è®¾ç½®é¡¹ç›®è·¯å¾„", command=self._set_projects_path)
        tools_menu.add_command(label="å¤‡ä»½æ‰€æœ‰å¯¹è¯", command=self._backup_all)

        # å¸®åŠ©èœå•
        help_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="å¸®åŠ©", menu=help_menu)
        help_menu.add_command(label="å…³äº", command=self._show_about)

        # åˆ›å»ºä¸»é¢æ¿ - ä½¿ç”¨ä¸‰æ å¸ƒå±€
        main_paned = ttk.PanedWindow(self.root, orient=tk.HORIZONTAL)
        main_paned.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)

        # å·¦ä¾§é¢æ¿ - é¡¹ç›®å’Œå¯¹è¯åˆ—è¡¨
        left_frame = ttk.Frame(main_paned)
        main_paned.add(left_frame, weight=1)

        # ç»Ÿè®¡é¢æ¿ï¼ˆé¡¶éƒ¨ï¼‰
        stats_frame = ttk.LabelFrame(left_frame, text="é¡¹ç›®ç»Ÿè®¡", padding=5)
        stats_frame.pack(fill=tk.X, padx=5, pady=5)

        # ç»Ÿè®¡ä¿¡æ¯æ˜¾ç¤º
        self.stats_text = tk.Text(stats_frame, height=4, wrap=tk.WORD, font=("Consolas", 9))
        self.stats_text.pack(fill=tk.X, padx=2, pady=2)

        # é…ç½®ç»Ÿè®¡æ–‡æœ¬æ ·å¼
        self.stats_text.config(state=tk.DISABLED, bg='#f0f0f0')

        # é¡¹ç›®é€‰æ‹©
        project_frame = ttk.LabelFrame(left_frame, text="é¡¹ç›®", padding=8)
        project_frame.pack(fill=tk.X, padx=5, pady=5)

        self.project_var = tk.StringVar()
        self.project_combo = ttk.Combobox(project_frame, textvariable=self.project_var,
                                          state="readonly", width=30)
        self.project_combo.pack(fill=tk.X)
        self.project_combo.bind('<<ComboboxSelected>>', self._on_project_select)

        # æœç´¢æ¡†
        search_frame = ttk.LabelFrame(left_frame, text="æœç´¢", padding=8)
        search_frame.pack(fill=tk.X, padx=5, pady=5)

        self.search_var = tk.StringVar()
        search_entry = ttk.Entry(search_frame, textvariable=self.search_var)
        search_entry.pack(fill=tk.X, pady=(0, 5))

        search_entry.bind('<Return>', self._search_conversations)
        ttk.Button(search_frame, text="æœç´¢", command=self._search_conversations).pack()
        ttk.Button(search_frame, text="æ¸…é™¤", command=self._clear_search).pack(pady=(5, 0))

        # å¯¹è¯åˆ—è¡¨
        list_frame = ttk.LabelFrame(left_frame, text="å¯¹è¯åˆ—è¡¨", padding=8)
        list_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)

        # åˆ›å»ºTreeview
        tree_frame = ttk.Frame(list_frame)
        tree_frame.pack(fill=tk.BOTH, expand=True)

        tree_scrollbar = ttk.Scrollbar(tree_frame)
        tree_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)

        columns = ("æ–‡ä»¶å", "ä¿®æ”¹æ—¶é—´", "æ¶ˆæ¯æ•°", "Token", "å¤§å°")
        self.conversation_tree = ttk.Treeview(tree_frame, columns=columns, show="headings",
                                           yscrollcommand=tree_scrollbar.set)
        self.conversation_tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        tree_scrollbar.config(command=self.conversation_tree.yview)

        # è®¾ç½®åˆ—æ ‡é¢˜å¹¶ç»‘å®šç‚¹å‡»æ’åºäº‹ä»¶
        self.conversation_tree.heading("æ–‡ä»¶å", text="æ–‡ä»¶å", command=lambda: self._sort_conversations("æ–‡ä»¶å"))
        self.conversation_tree.heading("ä¿®æ”¹æ—¶é—´", text="ä¿®æ”¹æ—¶é—´", command=lambda: self._sort_conversations("ä¿®æ”¹æ—¶é—´"))
        self.conversation_tree.heading("æ¶ˆæ¯æ•°", text="æ¶ˆæ¯æ•°", command=lambda: self._sort_conversations("æ¶ˆæ¯æ•°"))
        self.conversation_tree.heading("Token", text="Token", command=lambda: self._sort_conversations("Token"))
        self.conversation_tree.heading("å¤§å°", text="å¤§å°", command=lambda: self._sort_conversations("å¤§å°"))

        # è®¾ç½®åˆ—å®½
        self.conversation_tree.column("æ–‡ä»¶å", width=220)
        self.conversation_tree.column("ä¿®æ”¹æ—¶é—´", width=140)
        self.conversation_tree.column("æ¶ˆæ¯æ•°", width=70)
        self.conversation_tree.column("Token", width=80)
        self.conversation_tree.column("å¤§å°", width=70)

        # ç»‘å®šé€‰æ‹©äº‹ä»¶ - ç‚¹å‡»å³åˆ·æ–°
        self.conversation_tree.bind('<<TreeviewSelect>>', self._on_conversation_select)
        self.conversation_tree.bind('<Double-1>', self._on_conversation_double_click)
        self.conversation_tree.bind('<Button-3>', self._show_context_menu)

        # åˆ†é¡µæ§åˆ¶é¢æ¿
        pagination_frame = ttk.Frame(list_frame)
        pagination_frame.pack(fill=tk.X, pady=(5, 0))

        # åˆ†é¡µä¿¡æ¯æ ‡ç­¾
        self.page_info_label = ttk.Label(pagination_frame, text="ç¬¬ 1 é¡µï¼Œå…± 1 é¡µ")
        self.page_info_label.pack(side=tk.LEFT, padx=5)

        # åˆ†é¡µæŒ‰é’®
        pagination_buttons = ttk.Frame(pagination_frame)
        pagination_buttons.pack(side=tk.RIGHT)

        self.first_page_btn = ttk.Button(pagination_buttons, text="é¦–é¡µ", command=self._go_to_first_page, width=6)
        self.first_page_btn.pack(side=tk.LEFT, padx=1)

        self.prev_page_btn = ttk.Button(pagination_buttons, text="ä¸Šä¸€é¡µ", command=self._go_to_prev_page, width=8)
        self.prev_page_btn.pack(side=tk.LEFT, padx=1)

        # é¡µç è¾“å…¥æ¡†
        ttk.Label(pagination_buttons, text="è·³è½¬åˆ°").pack(side=tk.LEFT, padx=(10, 2))
        self.page_var = tk.StringVar(value="1")
        self.page_entry = ttk.Entry(pagination_buttons, textvariable=self.page_var, width=5)
        self.page_entry.pack(side=tk.LEFT, padx=1)
        self.page_entry.bind('<Return>', self._jump_to_page)
        ttk.Label(pagination_buttons, text="é¡µ").pack(side=tk.LEFT, padx=1)

        self.next_page_btn = ttk.Button(pagination_buttons, text="ä¸‹ä¸€é¡µ", command=self._go_to_next_page, width=8)
        self.next_page_btn.pack(side=tk.LEFT, padx=1)

        self.last_page_btn = ttk.Button(pagination_buttons, text="æœ«é¡µ", command=self._go_to_last_page, width=6)
        self.last_page_btn.pack(side=tk.LEFT, padx=1)

        # æ¯é¡µæ˜¾ç¤ºæ•°é‡é€‰æ‹©
        ttk.Label(pagination_buttons, text="æ¯é¡µæ˜¾ç¤º").pack(side=tk.LEFT, padx=(10, 2))
        self.page_size_var = tk.StringVar(value="50")
        page_size_combo = ttk.Combobox(pagination_buttons, textvariable=self.page_size_var,
                                      values=["20", "50", "100", "200"], state="readonly", width=6)
        page_size_combo.pack(side=tk.LEFT, padx=1)
        page_size_combo.bind('<<ComboboxSelected>>', self._on_page_size_change)
        ttk.Label(pagination_buttons, text="æ¡").pack(side=tk.LEFT, padx=1)

        # å³é”®èœå•
        self.context_menu = tk.Menu(self.root, tearoff=0)
        self.context_menu.add_command(label="åˆ é™¤å¯¹è¯", command=self._delete_conversation)
        self.context_menu.add_separator()
        self.context_menu.add_command(label="å¯¼å‡ºä¸ºMarkdown", command=self._export_conversation_markdown)
        self.context_menu.add_command(label="å¯¼å‡ºä¸ºJSON", command=self._export_conversation_json)

        # ä¸­é—´é¢æ¿ - æ¶ˆæ¯åˆ—è¡¨
        middle_frame = ttk.Frame(main_paned)
        main_paned.add(middle_frame, weight=1)

        # æ¶ˆæ¯åˆ—è¡¨é¢æ¿
        message_frame = ttk.LabelFrame(middle_frame, text="æ¶ˆæ¯åˆ—è¡¨", padding=8)
        message_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)

        # æ¶ˆæ¯åˆ—è¡¨
        msg_list_frame = ttk.Frame(message_frame)
        msg_list_frame.pack(fill=tk.BOTH, expand=True)

        msg_list_scrollbar = ttk.Scrollbar(msg_list_frame)
        msg_list_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)

        self.message_listbox = tk.Listbox(msg_list_frame, yscrollcommand=msg_list_scrollbar.set)
        self.message_listbox.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        msg_list_scrollbar.config(command=self.message_listbox.yview)

        # ç»‘å®šæ¶ˆæ¯é€‰æ‹©äº‹ä»¶
        self.message_listbox.bind('<<ListboxSelect>>', self._on_message_select)

        # å³ä¾§é¢æ¿ - å¯¹è¯å†…å®¹å’Œæ“ä½œ
        right_frame = ttk.Frame(main_paned)
        main_paned.add(right_frame, weight=2)

        # å¯¹è¯ä¿¡æ¯å·¥å…·æ 
        info_frame = ttk.Frame(right_frame)
        info_frame.pack(fill=tk.X, padx=5, pady=3)

        self.conversation_info_label = ttk.Label(info_frame, text="æœªé€‰æ‹©å¯¹è¯", font=("Arial", 10, "bold"))
        self.conversation_info_label.pack(side=tk.LEFT)

        # å¯¼å‡ºæŒ‰é’®
        export_frame = ttk.Frame(info_frame)
        export_frame.pack(side=tk.RIGHT)

        ttk.Button(export_frame, text="å¯¼å‡ºMD", command=self._export_current_markdown, width=8).pack(side=tk.LEFT, padx=2)
        ttk.Button(export_frame, text="å¯¼å‡ºJSON", command=self._export_current_json, width=8).pack(side=tk.LEFT, padx=2)

        # å¯¹è¯å†…å®¹æ˜¾ç¤º
        content_frame = ttk.LabelFrame(right_frame, text="å¯¹è¯å†…å®¹", padding=8)
        content_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)

        content_display_frame = ttk.Frame(content_frame)
        content_display_frame.pack(fill=tk.BOTH, expand=True)

        content_scrollbar = ttk.Scrollbar(content_display_frame)
        content_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)

        self.content_text = tk.Text(content_display_frame, wrap=tk.WORD, font=("Consolas", 10))
        self.content_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        content_scrollbar.config(command=self.content_text.yview)
        self.content_text.config(yscrollcommand=content_scrollbar.set)

        # æ“ä½œæŒ‰é’®
        button_frame = ttk.Frame(right_frame)
        button_frame.pack(fill=tk.X, padx=5, pady=3)

        ttk.Button(button_frame, text="åˆ é™¤å¯¹è¯", command=self._delete_conversation).pack(side=tk.LEFT, padx=5)
        ttk.Button(button_frame, text="åˆ·æ–°é¡¹ç›®", command=self._load_projects).pack(side=tk.RIGHT, padx=5)

        # è¿›åº¦æ¡æ¡†æ¶
        progress_frame = ttk.Frame(self.root)
        progress_frame.pack(side=tk.BOTTOM, fill=tk.X, padx=5, pady=2)

        # è¿›åº¦æ¡ï¼ˆé»˜è®¤éšè—ï¼‰
        self.progress_var = tk.DoubleVar()
        self.progress_bar = ttk.Progressbar(progress_frame, variable=self.progress_var,
                                          mode='determinate', length=200)
        self.progress_label = ttk.Label(progress_frame, text="")

        # çŠ¶æ€æ 
        self.status_bar = ttk.Label(self.root, text="å°±ç»ª", relief=tk.SUNKEN)
        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)

    def _load_projects(self):
        """åŠ è½½é¡¹ç›®æ•°æ®"""
        if not self.projects_path.exists():
            messagebox.showerror("é”™è¯¯", f"Projectsç›®å½•ä¸å­˜åœ¨: {self.projects_path}")
            return

        # æ˜¾ç¤ºè¿›åº¦æ¡
        self._show_progress("æ­£åœ¨æ‰«æé¡¹ç›®ç›®å½•...")
        self.status_bar.config(text="æ­£åœ¨åŠ è½½é¡¹ç›®æ•°æ®...")

        # åœ¨åå°çº¿ç¨‹ä¸­åŠ è½½æ•°æ®
        threading.Thread(target=self._load_projects_thread, daemon=True).start()

    def _load_projects_thread(self):
        """åå°çº¿ç¨‹åŠ è½½é¡¹ç›®æ•°æ®ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰"""
        try:
            start_time = time.time()
            self.projects_data = {}

            # è·å–æ‰€æœ‰é¡¹ç›®ç›®å½•
            self.root.after(0, lambda: self._update_progress(10, "æ­£åœ¨å‘ç°é¡¹ç›®ç›®å½•..."))
            project_dirs = [d for d in self.projects_path.iterdir() if d.is_dir()]

            if not project_dirs:
                self.root.after(0, lambda: self._hide_progress())
                self.root.after(0, lambda: self._update_projects_ui())
                return

            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†é¡¹ç›®
            max_workers = min(4, len(project_dirs))  # é™åˆ¶æœ€å¤§å¹¶å‘æ•°
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤æ‰€æœ‰é¡¹ç›®åˆ†æä»»åŠ¡
                self.root.after(0, lambda: self._update_progress(20, f"å‘ç° {len(project_dirs)} ä¸ªé¡¹ç›®ï¼Œå¼€å§‹åˆ†æ..."))
                future_to_project = {
                    executor.submit(self._analyze_project_concurrent, project_dir): project_dir
                    for project_dir in project_dirs
                }

                # æ”¶é›†ç»“æœ
                completed_count = 0
                total_projects = len(project_dirs)
                for future in concurrent.futures.as_completed(future_to_project):
                    project_dir = future_to_project[future]
                    try:
                        project_name, conversations = future.result()
                        if conversations:
                            self.projects_data[project_name] = conversations
                        completed_count += 1

                        # æ›´æ–°è¿›åº¦
                        progress = 20 + (completed_count / total_projects) * 70  # 20%-90%
                        self.root.after(0, lambda p=progress, c=completed_count, t=total_projects: self._update_progress(
                            p, f"æ­£åœ¨åˆ†æé¡¹ç›®... {c}/{t} ({p:.0f}%)"
                        ))

                    except Exception as e:
                        print(f"åˆ†æé¡¹ç›® {project_dir.name} æ—¶å‡ºé”™: {e}")

            # æ›´æ–°UI
            self.root.after(0, lambda: self._update_progress(95, "æ­£åœ¨æ›´æ–°ç•Œé¢..."))
            elapsed_time = time.time() - start_time
            self.root.after(0, lambda: self._update_projects_ui_with_stats(elapsed_time))
            self.root.after(0, lambda: self._hide_progress())

        except Exception as e:
            self.root.after(0, lambda: self._hide_progress())
            self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"åŠ è½½é¡¹ç›®å¤±è´¥: {e}"))
            self.root.after(0, lambda: self.status_bar.config(text="åŠ è½½å¤±è´¥"))

    def _analyze_project_concurrent(self, project_dir: Path) -> Tuple[str, List[Dict]]:
        """å¹¶å‘åˆ†æå•ä¸ªé¡¹ç›®"""
        project_name = project_dir.name
        conversations = []

        try:
            # è·å–é¡¹ç›®ä¸­çš„æ‰€æœ‰.jsonlæ–‡ä»¶
            jsonl_files = list(project_dir.glob("*.jsonl"))

            if not jsonl_files:
                return project_name, []

            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†å¯¹è¯æ–‡ä»¶
            max_file_workers = min(2, len(jsonl_files))  # æ¯ä¸ªé¡¹ç›®æœ€å¤š2ä¸ªå¹¶å‘æ–‡ä»¶å¤„ç†
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_file_workers) as file_executor:
                # æäº¤æ‰€æœ‰æ–‡ä»¶åˆ†æä»»åŠ¡
                future_to_file = {
                    file_executor.submit(self._analyze_conversation_file, jsonl_file): jsonl_file
                    for jsonl_file in jsonl_files
                }

                # æ”¶é›†ç»“æœ
                for future in concurrent.futures.as_completed(future_to_file):
                    jsonl_file = future_to_file[future]
                    try:
                        conv_info = future.result()
                        if conv_info:
                            conversations.append(conv_info)
                    except Exception as e:
                        print(f"åˆ†ææ–‡ä»¶ {jsonl_file.name} æ—¶å‡ºé”™: {e}")

            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
            conversations.sort(key=lambda x: x['modified_time'], reverse=True)
            return project_name, conversations

        except Exception as e:
            print(f"åˆ†æé¡¹ç›® {project_name} æ—¶å‡ºé”™: {e}")
            return project_name, []

    def _update_projects_ui_with_stats(self, elapsed_time: float):
        """æ›´æ–°é¡¹ç›®UIå¹¶æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡"""
        # æ›´æ–°é¡¹ç›®ä¸‹æ‹‰æ¡†
        project_names = list(self.projects_data.keys())
        self.project_combo['values'] = project_names

        if project_names:
            self.project_combo.set(project_names[0])
            self._on_project_select(None)

        # è®¡ç®—æ€»å¯¹è¯æ•°å’Œtokenæ•°
        total_conversations = sum(len(convs) for convs in self.projects_data.values())
        total_tokens = sum(
            sum(conv.get('total_tokens', 0) for conv in convs)
            for convs in self.projects_data.values()
        )

        # æ˜¾ç¤ºåŠ è½½ç»Ÿè®¡
        status_text = f"å·²åŠ è½½ {len(project_names)} ä¸ªé¡¹ç›®, {total_conversations} ä¸ªå¯¹è¯"
        if total_tokens > 0:
            token_str = self.token_calculator.format_tokens(total_tokens)
            status_text += f", {token_str} tokens"
        status_text += f" (è€—æ—¶: {elapsed_time:.2f}s)"

        self.status_bar.config(text=status_text)

    def _update_projects_ui(self):
        """æ›´æ–°é¡¹ç›®UI"""
        # æ›´æ–°é¡¹ç›®ä¸‹æ‹‰æ¡†
        project_names = list(self.projects_data.keys())
        self.project_combo['values'] = project_names

        if project_names:
            self.project_combo.set(project_names[0])
            self._on_project_select(None)

        self.status_bar.config(text=f"å·²åŠ è½½ {len(project_names)} ä¸ªé¡¹ç›®")

    def _analyze_conversation_file(self, file_path: Path) -> Optional[Dict]:
        """åˆ†æå•ä¸ªå¯¹è¯æ–‡ä»¶ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        try:
            # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´
            stat = file_path.stat()
            mtime = stat.st_mtime

            # åˆ›å»ºç¼“å­˜é”®
            cache_key = f"{file_path}:{mtime}"

            # æ£€æŸ¥ç¼“å­˜
            if cache_key in self._file_analysis_cache:
                return self._file_analysis_cache[cache_key]

            # åˆ†ææ–‡ä»¶
            result = self._perform_file_analysis(file_path, stat)

            # ç¼“å­˜ç»“æœ
            if result:
                self._cache_file_analysis(cache_key, result)

            return result

        except Exception as e:
            print(f"åˆ†ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None

    def _perform_file_analysis(self, file_path: Path, stat) -> Optional[Dict]:
        """å®é™…æ‰§è¡Œæ–‡ä»¶åˆ†æ"""
        try:
            # è¯»å–æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
            message_count = 0
            summary = None
            first_user_msg = None
            last_timestamp = None

            # Tokenè®¡ç®—ç›¸å…³
            conversation_data = []
            total_tokens = 0

            with open(file_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    if not line.strip():
                        continue

                    try:
                        data = json.loads(line)
                        conversation_data.append((line_num, data))

                        # ç»Ÿè®¡æ¶ˆæ¯æ•°é‡
                        if data.get('type') in ['user', 'assistant']:
                            message_count += 1

                            # è®°å½•ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä½œä¸ºé¢„è§ˆ
                            if first_user_msg is None and data.get('type') == 'user':
                                content = data.get('message', {}).get('content', '')
                                if isinstance(content, str):
                                    first_user_msg = content[:100] + '...' if len(content) > 100 else content
                                elif isinstance(content, list) and content and content[0].get('type') == 'text':
                                    text = content[0].get('text', '')
                                    first_user_msg = text[:100] + '...' if len(text) > 100 else text

                        # è·å–æ‘˜è¦
                        if data.get('type') == 'summary':
                            summary = data.get('summary', '').strip('"')

                        # è·å–æœ€åæ—¶é—´æˆ³
                        timestamp = data.get('timestamp')
                        if timestamp:
                            try:
                                last_timestamp = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                            except (ValueError, AttributeError):
                                pass

                    except json.JSONDecodeError:
                        continue

            # è®¡ç®—tokenä½¿ç”¨æƒ…å†µ
            token_analysis = self.token_calculator.analyze_conversation_tokens(conversation_data)
            total_tokens = token_analysis['total_tokens']

            return {
                'file_name': file_path.name,
                'file_path': str(file_path),
                'file_size': stat.st_size,
                'modified_time': datetime.fromtimestamp(stat.st_mtime),
                'created_time': datetime.fromtimestamp(stat.st_ctime),
                'message_count': message_count,
                'summary': summary,
                'first_user_msg': first_user_msg,
                'last_timestamp': last_timestamp,
                # æ–°å¢tokenç›¸å…³å­—æ®µ
                'total_tokens': total_tokens,
                'token_analysis': token_analysis
            }

        except Exception as e:
            print(f"åˆ†ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None

    def _cache_file_analysis(self, cache_key: str, result: Dict):
        """ç¼“å­˜æ–‡ä»¶åˆ†æç»“æœ"""
        # é™åˆ¶ç¼“å­˜å¤§å°
        if len(self._file_analysis_cache) >= self._file_cache_max_size:
            # åˆ é™¤ä¸€äº›æ—§ç¼“å­˜
            keys_to_remove = list(self._file_analysis_cache.keys())[:20]
            for key in keys_to_remove:
                del self._file_analysis_cache[key]

        self._file_analysis_cache[cache_key] = result

    def _on_project_select(self, event):
        """é¡¹ç›®é€‰æ‹©äº‹ä»¶å¤„ç†"""
        project_name = self.project_var.get()
        if not project_name or project_name not in self.projects_data:
            return

        self.current_project = project_name
        self.current_conversations = self.projects_data[project_name]
        self.filtered_conversations = self.current_conversations.copy()  # é‡ç½®ç­›é€‰åˆ—è¡¨

        # é‡ç½®æ’åºçŠ¶æ€å¹¶é»˜è®¤æŒ‰ä¿®æ”¹æ—¶é—´é™åºæ’åˆ—
        self.sort_column = "ä¿®æ”¹æ—¶é—´"
        self.sort_reverse = True  # é™åºï¼Œæœ€æ–°çš„åœ¨å‰

        # é‡ç½®åˆ†é¡µ
        self.current_page = 1
        self._update_pagination()

        # æ›´æ–°å¯¹è¯åˆ—è¡¨
        self._update_conversation_list()

        # è®¡ç®—é¡¹ç›®æ€»tokenæ•°
        total_tokens = sum(conv.get('total_tokens', 0) for conv in self.current_conversations)
        total_tokens_str = self.token_calculator.format_tokens(total_tokens)

        # æ›´æ–°ç»Ÿè®¡æ˜¾ç¤º
        self._update_stats_display()

        self.status_bar.config(text=f"é¡¹ç›®: {project_name} - {len(self.current_conversations)} ä¸ªå¯¹è¯, æ€»è®¡ {total_tokens_str} tokens")

    def _update_stats_display(self):
        """æ›´æ–°ç»Ÿè®¡æ˜¾ç¤ºé¢æ¿"""
        if not self.current_conversations:
            stats_text = "ğŸ“Š æš‚æ— æ•°æ®"
        else:
            # è®¡ç®—ç»Ÿè®¡æ•°æ®
            total_conversations = len(self.current_conversations)
            total_tokens = sum(conv.get('total_tokens', 0) for conv in self.current_conversations)
            total_messages = sum(conv.get('message_count', 0) for conv in self.current_conversations)
            total_file_size = sum(conv.get('file_size', 0) for conv in self.current_conversations)

            # è®¡ç®—å¹³å‡å€¼
            avg_tokens = total_tokens / total_conversations if total_conversations > 0 else 0
            avg_messages = total_messages / total_conversations if total_conversations > 0 else 0

            # æ ¼å¼åŒ–æ˜¾ç¤º
            stats_text = f"ğŸ“Š é¡¹ç›®ç»Ÿè®¡\n"
            stats_text += f"å¯¹è¯æ•°: {total_conversations} | æ¶ˆæ¯æ•°: {total_messages} | Tokenæ•°: {self.token_calculator.format_tokens(total_tokens)}\n"
            stats_text += f"å¹³å‡: {avg_messages:.1f} æ¶ˆæ¯/å¯¹è¯ | {self.token_calculator.format_tokens(avg_tokens)}/å¯¹è¯ | {self._format_file_size(total_file_size/total_conversations)}/å¯¹è¯"

            # æ·»åŠ å½“å‰ç­›é€‰ä¿¡æ¯
            if len(self.filtered_conversations) != len(self.current_conversations):
                stats_text += f"\nå½“å‰æ˜¾ç¤º: {len(self.filtered_conversations)}/{total_conversations} ä¸ªå¯¹è¯"

        # æ›´æ–°ç»Ÿè®¡æ–‡æœ¬
        self.stats_text.config(state=tk.NORMAL)
        self.stats_text.delete(1.0, tk.END)
        self.stats_text.insert(tk.END, stats_text)
        self.stats_text.config(state=tk.DISABLED)

    def _update_conversation_list(self):
        """æ›´æ–°å¯¹è¯åˆ—è¡¨ï¼ˆæ”¯æŒåˆ†é¡µï¼‰"""
        # ä¸´æ—¶è§£ç»‘é€‰æ‹©äº‹ä»¶ï¼Œé¿å…æ¸…ç©ºåˆ—è¡¨æ—¶è§¦å‘
        self.conversation_tree.unbind('<<TreeviewSelect>>')

        # æ¸…ç©ºåˆ—è¡¨
        for item in self.conversation_tree.get_children():
            self.conversation_tree.delete(item)

        # è®¡ç®—åˆ†é¡µèŒƒå›´
        start_idx = (self.current_page - 1) * self.page_size
        end_idx = start_idx + self.page_size

        # è·å–å½“å‰é¡µçš„å¯¹è¯
        page_conversations = self.filtered_conversations[start_idx:end_idx]

        # æ·»åŠ å½“å‰é¡µçš„å¯¹è¯
        for conv in page_conversations:
            token_count = conv.get('total_tokens', 0)
            token_str = self.token_calculator.format_tokens(token_count) if token_count > 0 else "æœªçŸ¥"

            # å¦‚æœæ˜¯æœç´¢ç»“æœï¼Œæ·»åŠ åŒ¹é…æ•°é‡æ ‡è¯†
            if 'matches' in conv:
                display_name = f"ğŸ” {conv['file_name']} ({len(conv['matches'])} åŒ¹é…)"
            else:
                display_name = conv['file_name']

            self.conversation_tree.insert("", tk.END,
                                       values=(
                                           display_name,
                                           conv['modified_time'].strftime("%Y-%m-%d %H:%M:%S"),
                                           conv['message_count'],
                                           token_str,
                                           self._format_file_size(conv['file_size'])
                                       ))

        # é‡æ–°ç»‘å®šé€‰æ‹©äº‹ä»¶
        self.conversation_tree.bind('<<TreeviewSelect>>', self._on_conversation_select)

        # æ›´æ–°åˆ†é¡µä¿¡æ¯
        self._update_pagination_info()

    def _sort_conversations(self, column: str):
        """æ’åºå¯¹è¯åˆ—è¡¨"""
        # å¦‚æœæ­£åœ¨æ’åºï¼Œç›´æ¥è¿”å›
        if self._sorting_in_progress:
            return

        # å–æ¶ˆä¹‹å‰çš„é˜»å¡å®šæ—¶å™¨
        if self._sort_block_timer:
            self.root.after_cancel(self._sort_block_timer)
            self._sort_block_timer = None

        self._sorting_in_progress = True

        try:
            # å¦‚æœç‚¹å‡»åŒä¸€åˆ—ï¼Œåˆ‡æ¢æ’åºæ–¹å‘
            if self.sort_column == column:
                self.sort_reverse = not self.sort_reverse
            else:
                self.sort_column = column
                self.sort_reverse = False

            # æ ¹æ®åˆ—åè¿›è¡Œæ’åº
            if column == "æ–‡ä»¶å":
                self.filtered_conversations.sort(key=lambda x: x['file_name'].lower(), reverse=self.sort_reverse)
            elif column == "ä¿®æ”¹æ—¶é—´":
                self.filtered_conversations.sort(key=lambda x: x['modified_time'], reverse=self.sort_reverse)
            elif column == "æ¶ˆæ¯æ•°":
                self.filtered_conversations.sort(key=lambda x: x['message_count'], reverse=self.sort_reverse)
            elif column == "Token":
                self.filtered_conversations.sort(key=lambda x: x.get('total_tokens', 0), reverse=self.sort_reverse)
            elif column == "å¤§å°":
                self.filtered_conversations.sort(key=lambda x: x['file_size'], reverse=self.sort_reverse)

            # é‡ç½®åˆ°ç¬¬ä¸€é¡µ
            self.current_page = 1
            self._update_pagination()

            # ä¿å­˜å½“å‰é€‰ä¸­çš„å¯¹è¯ï¼ˆå¦‚æœæœ‰ï¼‰
            selected_items = self.conversation_tree.selection()
            selected_file = None
            if selected_items:
                item = selected_items[0]
                item_values = self.conversation_tree.item(item, 'values')
                display_name = item_values[0]
                # å¦‚æœæ˜¯æœç´¢ç»“æœï¼Œæå–å®é™…æ–‡ä»¶å
                if display_name.startswith('ğŸ” '):
                    selected_file = display_name.split(' (')[0][2:]
                else:
                    selected_file = display_name

            # å®Œå…¨ç¦ç”¨é€‰æ‹©äº‹ä»¶ï¼ŒåŒ…æ‹¬ç§»é™¤æ‰€æœ‰ç»‘å®š
            self.conversation_tree.unbind('<<TreeviewSelect>>')

            # é¢å¤–ä¿æŠ¤ï¼šä¸´æ—¶ä¿®æ”¹é€‰æ‹©äº‹ä»¶å¤„ç†å‡½æ•°
            original_handler = self._on_conversation_select
            self._on_conversation_select = lambda event: None

            # æ›´æ–°æ˜¾ç¤º
            self._update_conversation_list_silent()

            # æ¢å¤ä¹‹å‰é€‰ä¸­çš„å¯¹è¯
            restored_item = None
            if selected_file:
                for item in self.conversation_tree.get_children():
                    item_values = self.conversation_tree.item(item, 'values')
                    display_name = item_values[0]
                    current_file = display_name.split(' (')[0][2:] if display_name.startswith('ğŸ” ') else display_name
                    if current_file == selected_file:
                        self.conversation_tree.selection_set(item)
                        restored_item = item
                        break
            # å¦‚æœæ²¡æœ‰æ¢å¤çš„é€‰æ‹©ï¼ˆå¯èƒ½æ˜¯ä¹‹å‰æ²¡æœ‰é€‰æ‹©ä»»ä½•å¯¹è¯ï¼‰ï¼Œä¸è§¦å‘é€‰æ‹©äº‹ä»¶

            # æ›´æ–°çŠ¶æ€æ æ˜¾ç¤ºæ’åºä¿¡æ¯
            direction = "é™åº" if self.sort_reverse else "å‡åº"
            self.status_bar.config(text=f"é¡¹ç›®: {self.current_project} - {len(self.current_conversations)} ä¸ªå¯¹è¯ (æŒ‰{column}{direction}æ’åˆ—)")

            # è®¾ç½®é˜»å¡å®šæ—¶å™¨ï¼Œç¡®ä¿åœ¨è¶³å¤Ÿé•¿çš„æ—¶é—´å†…é˜»æ­¢æ–°çš„æ’åº
            def restore_handlers():
                self._on_conversation_select = original_handler
                self.conversation_tree.bind('<<TreeviewSelect>>', self._on_conversation_select)

                # åªæœ‰åœ¨çœŸæ­£æ¢å¤äº†é€‰æ‹©æ—¶æ‰è§¦å‘é€‰æ‹©äº‹ä»¶
                if restored_item:
                    self.root.after(50, self._on_conversation_select_safe)
                # å¦‚æœæ²¡æœ‰æ¢å¤é€‰æ‹©ï¼ˆå³åŸæœ¬å°±æ²¡æœ‰é€‰æ‹©ä»»ä½•å¯¹è¯ï¼‰ï¼Œä¸è§¦å‘ä»»ä½•äº‹ä»¶

                self._sorting_in_progress = False
                self._sort_block_timer = None

            self._sort_block_timer = self.root.after(300, restore_handlers)

        except Exception as e:
            # å‡ºé”™æ—¶ç¡®ä¿çŠ¶æ€æ¢å¤
            self._sorting_in_progress = False
            if self._sort_block_timer:
                self.root.after_cancel(self._sort_block_timer)
                self._sort_block_timer = None
            # é‡æ–°ç»‘å®šé€‰æ‹©äº‹ä»¶
            self.conversation_tree.bind('<<TreeviewSelect>>', self._on_conversation_select)

    def _update_conversation_list_silent(self):
        """é™é»˜æ›´æ–°å¯¹è¯åˆ—è¡¨ï¼Œä¸è§¦å‘é€‰æ‹©äº‹ä»¶"""
        # æ¸…ç©ºåˆ—è¡¨
        for item in self.conversation_tree.get_children():
            self.conversation_tree.delete(item)

        # æ·»åŠ å¯¹è¯
        for conv in self.current_conversations:
            token_count = conv.get('total_tokens', 0)
            token_str = self.token_calculator.format_tokens(token_count) if token_count > 0 else "æœªçŸ¥"

            self.conversation_tree.insert("", tk.END,
                                       values=(
                                           conv['file_name'],
                                           conv['modified_time'].strftime("%Y-%m-%d %H:%M:%S"),
                                           conv['message_count'],
                                           token_str,
                                           self._format_file_size(conv['file_size'])
                                       ))

    def _on_conversation_select_safe(self):
        """å®‰å…¨çš„é€‰æ‹©äº‹ä»¶å¤„ç†ï¼Œé¿å…å¼¹çª—"""
        selection = self.conversation_tree.selection()
        if selection:
            # åªæœ‰åœ¨æœ‰é€‰ä¸­é¡¹ä¸”æœ‰å½“å‰å¯¹è¯æ•°æ®æ—¶æ‰æŸ¥çœ‹
            if self.current_conversation and self.current_messages:
                self._view_conversation(show_warning=False)
            # å¦‚æœæœ‰é€‰ä¸­é¡¹ä½†æ²¡æœ‰å¯¹è¯æ•°æ®ï¼Œå°è¯•åŠ è½½
            elif self.current_conversations:
                # è·å–é€‰ä¸­çš„å¯¹è¯ä¿¡æ¯å¹¶åŠ è½½
                conv = self._get_selected_conversation(show_warning=False)
                if conv:
                    self._view_conversation(show_warning=False)

    def _format_file_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if size_bytes == 0:
            return "0 B"

        units = ['B', 'KB', 'MB', 'GB', 'TB']
        size = float(size_bytes)

        for i, unit in enumerate(units):
            if size < 1024.0:
                if i == 0:  # B
                    return f"{int(size)} {unit}"
                else:  # KB, MB, GB, TB
                    return f"{size:.1f} {unit}"
            size /= 1024.0

        return f"{size:.1f} PB"  # PB for extremely large files

    def _search_conversations(self, event=None):
        """æœç´¢å¯¹è¯"""
        keyword = self.search_var.get().strip()
        if not keyword:
            return

        if not self.current_project or not self.current_conversations:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©é¡¹ç›®")
            return

        # æ˜¾ç¤ºæœç´¢è¿›åº¦æ¡
        self._show_progress(f"æ­£åœ¨æœç´¢ '{keyword}'...")
        self.status_bar.config(text="æ­£åœ¨æœç´¢...")

        # åœ¨åå°çº¿ç¨‹ä¸­æœç´¢
        threading.Thread(target=self._search_conversations_thread, args=(keyword,), daemon=True).start()

    def _search_conversations_thread(self, keyword: str):
        """åå°çº¿ç¨‹æœç´¢å¯¹è¯ï¼ˆä¼˜åŒ–ç‰ˆï¼Œå¸¦è¿›åº¦æ¡ï¼‰"""
        try:
            # æ£€æŸ¥æœç´¢ç¼“å­˜
            self.root.after(0, lambda: self._update_progress(20, "æ£€æŸ¥æœç´¢ç¼“å­˜..."))
            cache_key = f"{self.current_project}:{keyword}"
            if cache_key in self._search_cache:
                cached_results = self._search_cache[cache_key]
                self.root.after(0, lambda: self._update_progress(100, f"ä»ç¼“å­˜åŠ è½½ç»“æœ"))
                self.root.after(0, lambda: self._show_search_results(cached_results, keyword))
                self.root.after(0, lambda: self._hide_progress())
                self.root.after(0, lambda: self.status_bar.config(text=f"æœç´¢ '{keyword}' æ‰¾åˆ° {len(cached_results)} ä¸ªå¯¹è¯ (ç¼“å­˜)"))
                return

            # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
            self.root.after(0, lambda: self._update_progress(30, "ç¼–è¯‘æœç´¢æ¨¡å¼..."))
            start_time = time.time()
            pattern = re.compile(keyword, re.IGNORECASE)

            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æœç´¢
            self.root.after(0, lambda: self._update_progress(50, f"æœç´¢ {len(self.current_conversations)} ä¸ªå¯¹è¯..."))
            if len(self.current_conversations) > 5:
                results = self._search_conversations_parallel(pattern)
            else:
                results = self._search_conversations_sequential(pattern)

            # ç¼“å­˜æœç´¢ç»“æœ
            self.root.after(0, lambda: self._update_progress(80, "ç¼“å­˜æœç´¢ç»“æœ..."))
            self._cache_search_results(cache_key, results)

            search_time = time.time() - start_time

            # æ›´æ–°UI
            self.root.after(0, lambda: self._update_progress(95, "æ›´æ–°æ˜¾ç¤ºç»“æœ..."))
            self.root.after(0, lambda: self._show_search_results(results, keyword))
            self.root.after(0, lambda: self._hide_progress())
            self.root.after(0, lambda: self.status_bar.config(
                text=f"æœç´¢ '{keyword}' æ‰¾åˆ° {len(results)} ä¸ªå¯¹è¯ (è€—æ—¶: {search_time:.2f}s)"
            ))

        except re.error as e:
            self.root.after(0, lambda: self._hide_progress())
            self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"æœç´¢è¡¨è¾¾å¼æ— æ•ˆ: {e}"))
            self.root.after(0, lambda: self.status_bar.config(text="æœç´¢å¤±è´¥"))
        except Exception as e:
            self.root.after(0, lambda: self._hide_progress())
            self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"æœç´¢å¤±è´¥: {e}"))
            self.root.after(0, lambda: self.status_bar.config(text="æœç´¢å¤±è´¥"))

    def _search_conversations_parallel(self, pattern: re.Pattern) -> List[Dict]:
        """å¹¶å‘æœç´¢å¯¹è¯"""
        results = []
        max_workers = min(4, len(self.current_conversations))

        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æœç´¢ä»»åŠ¡
            future_to_conv = {
                executor.submit(self._search_in_conversation, conv, pattern): conv
                for conv in self.current_conversations
            }

            # æ”¶é›†ç»“æœ
            for future in concurrent.futures.as_completed(future_to_conv):
                conv = future_to_conv[future]
                try:
                    matches = future.result()
                    if matches:
                        result = conv.copy()
                        result['matches'] = matches
                        results.append(result)
                except Exception as e:
                    print(f"æœç´¢å¯¹è¯ {conv['file_name']} æ—¶å‡ºé”™: {e}")

        return results

    def _search_conversations_sequential(self, pattern: re.Pattern) -> List[Dict]:
        """é¡ºåºæœç´¢å¯¹è¯ï¼ˆç”¨äºå°‘é‡å¯¹è¯ï¼‰"""
        results = []

        for conv in self.current_conversations:
            matches = self._search_in_conversation(conv, pattern)
            if matches:
                result = conv.copy()
                result['matches'] = matches
                results.append(result)

        return results

    def _cache_search_results(self, cache_key: str, results: List[Dict]):
        """ç¼“å­˜æœç´¢ç»“æœ"""
        # é™åˆ¶ç¼“å­˜å¤§å°
        if len(self._search_cache) >= self._search_cache_max_size:
            # åˆ é™¤æœ€æ—§çš„ç¼“å­˜é¡¹
            oldest_key = next(iter(self._search_cache))
            del self._search_cache[oldest_key]

        self._search_cache[cache_key] = results

    def _search_in_conversation(self, conv: Dict, pattern: re.Pattern) -> List[Dict]:
        """åœ¨å•ä¸ªå¯¹è¯ä¸­æœç´¢ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        matches = []

        try:
            # å…ˆæ£€æŸ¥é¢„è§ˆæ–‡æœ¬ï¼Œå¦‚æœé¢„è§ˆæ–‡æœ¬åŒ¹é…åˆ™ç›´æ¥è¿”å›
            first_user_msg = conv.get('first_user_msg', '')
            summary = conv.get('summary', '')

            # å¿«é€Ÿæ£€æŸ¥é¢„è§ˆå’Œæ‘˜è¦
            quick_content = f"{first_user_msg} {summary}"
            if pattern.search(quick_content):
                # å¦‚æœé¢„è§ˆåŒ¹é…ï¼Œè¿”å›ä¸€ä¸ªå¿«é€ŸåŒ¹é…æ ‡è®°
                return [{
                    'line_number': 0,
                    'field_name': 'preview',
                    'message_type': 'quick_match',
                    'timestamp': conv.get('last_timestamp'),
                    'preview': True
                }]

            # å¦‚æœå¿«é€ŸåŒ¹é…å¤±è´¥ï¼Œè¿›è¡Œå…¨æ–‡æœç´¢
            with open(conv['file_path'], 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    if not line.strip():
                        continue

                    try:
                        data = json.loads(line)

                        # ä½¿ç”¨å¿«é€Ÿå†…å®¹æå–
                        content_text = self._extract_searchable_text(data)
                        if content_text and pattern.search(content_text):
                            matches.append({
                                'line_number': line_num,
                                'field_name': 'content',
                                'message_type': data.get('type'),
                                'timestamp': data.get('timestamp'),
                                'preview': False
                            })

                            # é™åˆ¶åŒ¹é…æ•°é‡ï¼Œé¿å…è¿”å›è¿‡å¤šç»“æœ
                            if len(matches) >= 10:
                                break

                    except json.JSONDecodeError:
                        continue

        except Exception as e:
            print(f"æœç´¢å¯¹è¯å¤±è´¥ {conv['file_path']}: {e}")

        return matches

    def _extract_searchable_text(self, data: Dict) -> str:
        """å¿«é€Ÿæå–å¯æœç´¢çš„æ–‡æœ¬å†…å®¹"""
        try:
            msg_type = data.get('type', '')

            if msg_type == 'summary':
                return data.get('summary', '')

            elif msg_type in ['user', 'assistant']:
                content = data.get('message', {}).get('content', '')
                if isinstance(content, str):
                    return content
                elif isinstance(content, list):
                    # åªæå–æ–‡æœ¬å†…å®¹ï¼Œè·³è¿‡å›¾ç‰‡å’Œå…¶ä»–ç±»å‹
                    text_parts = []
                    for item in content:
                        if item.get('type') == 'text':
                            text_parts.append(item.get('text', ''))
                    return ' '.join(text_parts)

            return ''
        except Exception:
            return ''

    def _show_search_results(self, results: List[Dict], keyword: str):
        """æ˜¾ç¤ºæœç´¢ç»“æœï¼ˆæ”¯æŒåˆ†é¡µï¼‰"""
        # è®¾ç½®ç­›é€‰åˆ—è¡¨ä¸ºæœç´¢ç»“æœ
        self.filtered_conversations = results

        # é‡ç½®åˆ°ç¬¬ä¸€é¡µ
        self.current_page = 1
        self._update_pagination()

        # æ›´æ–°å¯¹è¯åˆ—è¡¨æ˜¾ç¤º
        self._update_conversation_list()

        # æ›´æ–°ç»Ÿè®¡æ˜¾ç¤º
        self._update_stats_display()

        self.status_bar.config(text=f"æœç´¢ '{keyword}' æ‰¾åˆ° {len(results)} ä¸ªå¯¹è¯")

    def _clear_search(self):
        """æ¸…é™¤æœç´¢"""
        self.search_var.set("")
        if self.current_project:
            # æ¢å¤åŸå§‹å¯¹è¯åˆ—è¡¨
            self.filtered_conversations = self.current_conversations.copy()
            self.current_page = 1
            self._update_pagination()
            self._update_conversation_list()
            self.status_bar.config(text=f"é¡¹ç›®: {self.current_project} - {len(self.current_conversations)} ä¸ªå¯¹è¯")

    def _on_conversation_select(self, event):
        """å¯¹è¯é€‰æ‹©äº‹ä»¶ - ç‚¹å‡»å³è‡ªåŠ¨åˆ·æ–°"""
        # å¦‚æœæ­£åœ¨æ’åºï¼Œä¸å¤„ç†é€‰æ‹©äº‹ä»¶
        if self._sorting_in_progress:
            return

        # åªæœ‰åœ¨æœ‰é€‰ä¸­é¡¹æ—¶æ‰æŸ¥çœ‹å¯¹è¯ï¼Œé¿å…ç•Œé¢æ¸…ç©ºæ—¶çš„è¯¯è§¦å‘
        selection = self.conversation_tree.selection()
        if selection:
            self._view_conversation()

    def _on_conversation_double_click(self, event):
        """å¯¹è¯åŒå‡»äº‹ä»¶"""
        self._view_conversation(show_warning=True)

    def _on_message_select(self, event):
        """æ¶ˆæ¯é€‰æ‹©äº‹ä»¶"""
        selection = self.message_listbox.curselection()
        if selection:
            index = selection[0]
            self.conversation_viewer.display_message_content(self.content_text, self.status_bar, index)

    def _show_context_menu(self, event):
        """æ˜¾ç¤ºå³é”®èœå•"""
        # é€‰æ‹©ç‚¹å‡»çš„é¡¹ç›®
        item = self.conversation_tree.identify('item', event.x, event.y)
        if item:
            self.conversation_tree.selection_set(item)
            self.context_menu.post(event.x_root, event.y_root)

    def _get_selected_conversation(self, show_warning: bool = True) -> Optional[Dict]:
        """è·å–é€‰ä¸­çš„å¯¹è¯"""
        selection = self.conversation_tree.selection()
        if not selection:
            if show_warning:
                messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©å¯¹è¯")
            return None

        item = selection[0]
        item_values = self.conversation_tree.item(item, 'values')
        display_name = item_values[0]  # æ–‡ä»¶ååˆ—

        # å¦‚æœæ˜¯æœç´¢ç»“æœï¼Œæå–å®é™…æ–‡ä»¶å
        if display_name.startswith('ğŸ” '):
            # æå–çœŸå®æ–‡ä»¶åï¼šå»æ‰æœç´¢æ ‡è¯†å’ŒåŒ¹é…æ•°é‡
            file_name = display_name.split(' (')[0][2:]
        else:
            file_name = display_name

        # æŸ¥æ‰¾å¯¹åº”çš„å¯¹è¯ä¿¡æ¯
        for conv in self.current_conversations:
            if conv['file_name'] == file_name:
                return conv

        return None

    def update_conversation_content(self, conversation_info, messages):
        """æ›´æ–°å¯¹è¯å†…å®¹æ˜¾ç¤ºåŒºåŸŸ"""
        self.current_conversation = conversation_info
        self.current_messages = messages

        # æ›´æ–°å¯¹è¯ä¿¡æ¯æ ‡ç­¾
        file_name = conversation_info['file_name']
        message_count = len(messages)
        token_count = conversation_info.get('total_tokens', 0)
        token_str = self.token_calculator.format_tokens(token_count) if token_count > 0 else "æœªçŸ¥"

        self.conversation_info_label.config(text=f"{file_name} ({message_count} æ¡æ¶ˆæ¯, {token_str} tokens)")

        # å¡«å……æ¶ˆæ¯åˆ—è¡¨
        self.conversation_viewer.populate_message_list(self.message_listbox)

        # å¦‚æœæœ‰æ¶ˆæ¯ï¼Œé»˜è®¤é€‰ä¸­ç¬¬ä¸€æ¡
        if messages:
            self.message_listbox.selection_set(0)
            self.conversation_viewer.display_message_content(self.content_text, self.status_bar, 0)
        else:
            self.content_text.delete(1.0, tk.END)
            self.content_text.insert(tk.END, "æ­¤å¯¹è¯æš‚æ— å†…å®¹")

    def _view_conversation(self, show_warning: bool = False):
        """æŸ¥çœ‹å¯¹è¯"""
        conv = self._get_selected_conversation(show_warning)
        if not conv:
            return

        # æ˜¾ç¤ºå¯¹è¯å†…å®¹
        self.conversation_viewer.show_conversation(conv['file_path'], conv)

    def _delete_conversation(self):
        """åˆ é™¤å¯¹è¯"""
        conv = self._get_selected_conversation()
        if not conv:
            return

        # ç¡®è®¤åˆ é™¤
        token_count = conv.get('total_tokens', 0)
        token_str = self.token_calculator.format_tokens(token_count) if token_count > 0 else "æœªçŸ¥"

        result = messagebox.askyesno(
            "ç¡®è®¤åˆ é™¤",
            f"ç¡®å®šè¦åˆ é™¤å¯¹è¯ '{conv['file_name']}' å—ï¼Ÿ\n\n"
            f"æ­¤æ“ä½œä¸å¯æ¢å¤ï¼\n\n"
            f"æ–‡ä»¶å¤§å°: {self._format_file_size(conv['file_size'])}\n"
            f"æ¶ˆæ¯æ•°é‡: {conv['message_count']}\n"
            f"Tokenæ•°é‡: {token_str}"
        )

        if not result:
            return

        try:
            # åˆ é™¤æ–‡ä»¶
            os.remove(conv['file_path'])

            # å®‰å…¨åœ°ä»æ•°æ®ä¸­ç§»é™¤ - ä½¿ç”¨æ–‡ä»¶è·¯å¾„åŒ¹é…è€Œä¸æ˜¯å¯¹è±¡å¼•ç”¨
            removed = False
            for i, conv_item in enumerate(self.current_conversations[:]):
                if conv_item['file_path'] == conv['file_path']:
                    self.current_conversations.pop(i)
                    removed = True
                    break

            # åŒæ ·ä»projects_dataä¸­ç§»é™¤
            if removed and self.current_project in self.projects_data:
                for i, conv_item in enumerate(self.projects_data[self.current_project][:]):
                    if conv_item['file_path'] == conv['file_path']:
                        self.projects_data[self.current_project].pop(i)
                        break

            # ä»filtered_conversationsä¸­ç§»é™¤
            for i, conv_item in enumerate(self.filtered_conversations[:]):
                if conv_item['file_path'] == conv['file_path']:
                    self.filtered_conversations.pop(i)
                    break

            # æ¸…ç†ç›¸å…³ç¼“å­˜
            self._cleanup_deleted_conversation_cache(conv['file_path'])

            # æ£€æŸ¥å½“å‰é¡µæ˜¯å¦è¿˜æœ‰æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™è·³è½¬åˆ°ä¸Šä¸€é¡µ
            if self.filtered_conversations and self.current_page > 1:
                start_idx = (self.current_page - 1) * self.page_size
                if start_idx >= len(self.filtered_conversations):
                    self.current_page = max(1, self.current_page - 1)

            # æ›´æ–°åˆ†é¡µçŠ¶æ€
            self._update_pagination()

            # æ›´æ–°UI
            self._update_conversation_list()
            # æ¸…ç©ºå¯¹è¯å†…å®¹æ˜¾ç¤ºåŒºåŸŸ
            self.conversation_info_label.config(text="æœªé€‰æ‹©å¯¹è¯")
            self.message_listbox.delete(0, tk.END)
            self.content_text.delete(1.0, tk.END)

            # æ›´æ–°ç»Ÿè®¡æ˜¾ç¤º
            self._update_stats_display()

            messagebox.showinfo("æˆåŠŸ", f"å·²åˆ é™¤å¯¹è¯: {conv['file_name']}")
            self.status_bar.config(text=f"å·²åˆ é™¤å¯¹è¯ï¼Œå‰©ä½™ {len(self.current_conversations)} ä¸ª")

        except ValueError as e:
            if "remove(x): x not in list" in str(e):
                messagebox.showinfo("æç¤º", f"å¯¹è¯ '{conv['file_name']}' å·²ä»åˆ—è¡¨ä¸­ç§»é™¤")
                # å¼ºåˆ¶åˆ·æ–°ç•Œé¢
                self._load_projects()
            else:
                messagebox.showerror("é”™è¯¯", f"åˆ é™¤å¤±è´¥: {e}")
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"åˆ é™¤å¤±è´¥: {e}")

    def _cleanup_deleted_conversation_cache(self, file_path: str):
        """æ¸…ç†å·²åˆ é™¤å¯¹è¯çš„ç›¸å…³ç¼“å­˜"""
        try:
            # æ¸…ç†æ–‡ä»¶åˆ†æç¼“å­˜
            file_path_obj = Path(file_path)
            cache_keys_to_remove = []

            for cache_key in self._file_analysis_cache:
                if cache_key.startswith(str(file_path_obj)):
                    cache_keys_to_remove.append(cache_key)

            for key in cache_keys_to_remove:
                del self._file_analysis_cache[key]

            # æ¸…ç†æœç´¢ç¼“å­˜ï¼ˆå¯èƒ½åŒ…å«è¯¥æ–‡ä»¶çš„æœç´¢ç»“æœï¼‰
            search_cache_keys_to_remove = []
            for cache_key in self._search_cache:
                # æ£€æŸ¥æœç´¢ç»“æœä¸­æ˜¯å¦åŒ…å«å·²åˆ é™¤çš„æ–‡ä»¶
                cached_results = self._search_cache[cache_key]
                for result in cached_results:
                    if result.get('file_path') == file_path:
                        search_cache_keys_to_remove.append(cache_key)
                        break

            for key in search_cache_keys_to_remove:
                del self._search_cache[key]

            # æ¸…ç†tokenè®¡ç®—å™¨ä¸­çš„æ¶ˆæ¯ç¼“å­˜
            if hasattr(self.token_calculator, '_message_token_cache'):
                token_cache_keys_to_remove = []
                for cache_key in self.token_calculator._message_token_cache:
                    # ç®€å•çš„æ¸…ç†ç­–ç•¥ï¼šæ¸…ç†æ‰€æœ‰ç¼“å­˜ï¼Œå› ä¸ºæ— æ³•ç²¾ç¡®å¯¹åº”æ–‡ä»¶
                    token_cache_keys_to_remove.append(cache_key)

                # é™åˆ¶æ¸…ç†æ•°é‡ï¼Œé¿å…æ¸…ç†è¿‡å¤š
                if len(token_cache_keys_to_remove) > 100:
                    token_cache_keys_to_remove = token_cache_keys_to_remove[:100]

                for key in token_cache_keys_to_remove:
                    del self.token_calculator._message_token_cache[key]

        except Exception as e:
            print(f"æ¸…ç†ç¼“å­˜æ—¶å‡ºé”™: {e}")

    def _export_conversation_markdown(self):
        """å¯¼å‡ºå¯¹è¯ä¸ºMarkdown"""
        conv = self._get_selected_conversation()
        if not conv:
            return

        filename = filedialog.asksaveasfilename(
            defaultextension=".md",
            initialfile=conv['file_name'].replace('.jsonl', '.md'),
            filetypes=[("Markdownæ–‡ä»¶", "*.md"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )

        if not filename:
            return

        try:
            self._export_to_markdown(conv['file_path'], filename)
            messagebox.showinfo("æˆåŠŸ", f"å·²å¯¼å‡ºåˆ°: {filename}")
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºå¤±è´¥: {e}")

    def _export_conversation_json(self):
        """å¯¼å‡ºå¯¹è¯ä¸ºJSON"""
        conv = self._get_selected_conversation()
        if not conv:
            return

        filename = filedialog.asksaveasfilename(
            defaultextension=".json",
            initialfile=conv['file_name'].replace('.jsonl', '.json'),
            filetypes=[("JSONæ–‡ä»¶", "*.json"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )

        if not filename:
            return

        try:
            self._export_to_json(conv['file_path'], filename)
            messagebox.showinfo("æˆåŠŸ", f"å·²å¯¼å‡ºåˆ°: {filename}")
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºå¤±è´¥: {e}")

    def _export_current_markdown(self):
        """å¯¼å‡ºå½“å‰å¯¹è¯ä¸ºMarkdown"""
        if not self.current_conversation:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©å¯¹è¯")
            return

        try:
            self.conversation_viewer.export_current_conversation('markdown')
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºå¤±è´¥: {e}")

    def _export_current_json(self):
        """å¯¼å‡ºå½“å‰å¯¹è¯ä¸ºJSON"""
        if not self.current_conversation:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©å¯¹è¯")
            return

        try:
            self.conversation_viewer.export_current_conversation('json')
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºå¤±è´¥: {e}")

    def _export_to_markdown(self, file_path: str, output_path: str):
        """å¯¼å‡ºä¸ºMarkdownæ ¼å¼"""
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        # è·å–å¯¹è¯åŸºæœ¬ä¿¡æ¯
        file_name = Path(file_path).stem
        messages = []
        summary = ""
        conversation_data = []

        for line_num, line in enumerate(lines, 1):
            if not line.strip():
                continue
            try:
                data = json.loads(line)
                conversation_data.append((line_num, data))

                if data.get('type') == 'summary':
                    summary = data.get('summary', '').strip('"')

                elif data.get('type') in ['user', 'assistant']:
                    msg_type = data.get('type')
                    content = data.get('message', {}).get('content', '')
                    timestamp = data.get('timestamp', '')

                    # å¤„ç†å†…å®¹æ ¼å¼
                    if isinstance(content, str):
                        formatted_content = content
                    elif isinstance(content, list):
                        formatted_content = ""
                        for item in content:
                            if item.get('type') == 'text':
                                formatted_content += item.get('text', '')

                    messages.append({
                        'type': msg_type,
                        'content': formatted_content,
                        'timestamp': timestamp,
                        'raw_data': data
                    })

            except json.JSONDecodeError:
                continue

        # è®¡ç®—tokenç»Ÿè®¡
        token_analysis = self.token_calculator.analyze_conversation_tokens(conversation_data)
        cost_estimate = self.token_calculator.get_token_cost_estimate(token_analysis['total_tokens'])

        # ç”ŸæˆMarkdownå†…å®¹
        markdown_content = f"# {file_name}\n\n"

        # æ·»åŠ tokenç»Ÿè®¡æŠ¥å‘Š
        markdown_content += "## ğŸ“Š Tokenç»Ÿè®¡æŠ¥å‘Š\n\n"
        markdown_content += f"- **æ€»Tokenæ•°**: {self.token_calculator.format_tokens(token_analysis['total_tokens'])}\n"
        markdown_content += f"- **ç”¨æˆ·Token**: {self.token_calculator.format_tokens(token_analysis['user_tokens'])}\n"
        markdown_content += f"- **åŠ©æ‰‹Token**: {self.token_calculator.format_tokens(token_analysis['assistant_tokens'])}\n"
        markdown_content += f"- **æ‘˜è¦Token**: {self.token_calculator.format_tokens(token_analysis['summary_tokens'])}\n"
        markdown_content += f"- **æ¶ˆæ¯æ•°é‡**: {token_analysis['message_count']}\n"
        markdown_content += f"- **å¹³å‡Token/æ¶ˆæ¯**: {token_analysis['avg_tokens_per_message']}\n\n"

        markdown_content += "### ğŸ’° æˆæœ¬ä¼°ç®—\n\n"
        markdown_content += f"- **æ¨¡å‹**: {cost_estimate['model']}\n"
        markdown_content += f"- **è¾“å…¥æˆæœ¬**: ${cost_estimate['input_cost']:.4f}\n"
        markdown_content += f"- **è¾“å‡ºæˆæœ¬**: ${cost_estimate['output_cost']:.4f}\n"
        markdown_content += f"- **æ€»æˆæœ¬**: ${cost_estimate['total_cost']:.4f}\n\n"

        markdown_content += "---\n\n"

        if summary:
            markdown_content += f"## æ‘˜è¦\n{summary}\n\n"

        markdown_content += "## å¯¹è¯å†…å®¹\n\n"

        for i, msg in enumerate(messages, 1):
            role_name = "ğŸ‘¤ ç”¨æˆ·" if msg['type'] == 'user' else "ğŸ¤– åŠ©æ‰‹"
            timestamp_str = ""
            if msg['timestamp']:
                try:
                    dt = datetime.fromisoformat(msg['timestamp'].replace('Z', '+00:00'))
                    timestamp_str = f" ({dt.strftime('%Y-%m-%d %H:%M:%S')})"
                except:
                    pass

            # è®¡ç®—æ¶ˆæ¯tokenæ•°
            msg_tokens = self.token_calculator.count_message_tokens(msg['raw_data'])

            markdown_content += f"### {role_name} {i}{timestamp_str} ({self.token_calculator.format_tokens(msg_tokens)} tokens)\n\n"
            markdown_content += f"{msg['content']}\n\n"
            markdown_content += "---\n\n"

        # å†™å…¥æ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)

    def _export_to_json(self, file_path: str, output_path: str):
        """å¯¼å‡ºä¸ºJSONæ ¼å¼"""
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        # è¯»å–å¹¶è¿‡æ»¤æ•°æ®ï¼Œè®¡ç®—token
        conversation_data = []
        exported_data = []

        for line_num, line in enumerate(lines, 1):
            if not line.strip():
                continue
            try:
                data = json.loads(line)
                conversation_data.append((line_num, data))
                exported_data.append(data)
            except json.JSONDecodeError:
                continue

        # è®¡ç®—tokenç»Ÿè®¡
        token_analysis = self.token_calculator.analyze_conversation_tokens(conversation_data)
        cost_estimate = self.token_calculator.get_token_cost_estimate(token_analysis['total_tokens'])

        # æ„å»ºå®Œæ•´çš„å¯¼å‡ºæ•°æ®
        complete_export_data = {
            "metadata": {
                "file_name": Path(file_path).name,
                "export_time": datetime.now().isoformat(),
                "total_messages": len(exported_data),
                "token_analysis": token_analysis,
                "cost_estimate": cost_estimate,
                "calculator_mode": "ç²¾ç¡®æ¨¡å¼" if self.token_calculator.precise_mode else "ä¼°ç®—æ¨¡å¼"
            },
            "messages": []
        }

        # ä¸ºæ¯ä¸ªæ¶ˆæ¯æ·»åŠ tokenä¿¡æ¯
        for line_num, data in conversation_data:
            msg_data = data.copy()
            msg_data["line_number"] = line_num
            msg_data["token_count"] = self.token_calculator.count_message_tokens(data)
            complete_export_data["messages"].append(msg_data)

        # å†™å…¥JSONæ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(complete_export_data, f, ensure_ascii=False, indent=2)

    def _set_projects_path(self):
        """è®¾ç½®é¡¹ç›®è·¯å¾„"""
        path = filedialog.askdirectory(
            title="é€‰æ‹©Claude Projectsç›®å½•",
            initialdir=str(self.projects_path)
        )

        if path:
            self.projects_path = Path(path)
            self._load_projects()

    def _backup_all(self):
        """å¤‡ä»½æ‰€æœ‰å¯¹è¯"""
        if not self.projects_data:
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰æ•°æ®å¯å¤‡ä»½")
            return

        backup_dir = filedialog.askdirectory(title="é€‰æ‹©å¤‡ä»½ç›®å½•")
        if not backup_dir:
            return

        try:
            backup_path = Path(backup_dir) / f"claude_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            backup_path.mkdir(parents=True, exist_ok=True)

            backed_up_files = 0

            for project_name, conversations in self.projects_data.items():
                # ä¸ºæ¯ä¸ªé¡¹ç›®åˆ›å»ºå­ç›®å½•
                project_backup_dir = backup_path / project_name
                project_backup_dir.mkdir(exist_ok=True)

                for conv in conversations:
                    source_file = Path(conv['file_path'])
                    target_file = project_backup_dir / conv['file_name']

                    import shutil
                    shutil.copy2(source_file, target_file)
                    backed_up_files += 1

            messagebox.showinfo("æˆåŠŸ", f"å¤‡ä»½å®Œæˆï¼\nå·²å¤‡ä»½ {backed_up_files} ä¸ªæ–‡ä»¶åˆ°:\n{backup_path}")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¤‡ä»½å¤±è´¥: {e}")

    def _on_closing(self):
        """çª—å£å…³é—­äº‹ä»¶å¤„ç†"""
        try:
            self.cleanup()
            self.root.destroy()
        except Exception as e:
            print(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}")
            self.root.destroy()

    def _show_about(self):
        """æ˜¾ç¤ºå…³äºä¿¡æ¯"""
        # è·å–ç¼“å­˜ç»Ÿè®¡
        token_cache_stats = getattr(self.token_calculator, 'cache_hits', 0), getattr(self.token_calculator, 'cache_misses', 0)
        token_hits, token_misses = token_cache_stats
        token_total = token_hits + token_misses
        token_hit_rate = (token_hits / token_total * 100) if token_total > 0 else 0

        search_cache_size = len(self._search_cache)
        file_cache_size = len(getattr(self, '_file_analysis_cache', {}))

        about_text = f"""Claude Code å†å²å¯¹è¯ç®¡ç†å™¨ - GUIç‰ˆæœ¬

ç‰ˆæœ¬: 2.0.0 - UIä½“éªŒä¼˜åŒ–ç‰ˆ
ä½œè€…: Claude

åŠŸèƒ½ç‰¹æ€§:
â€¢ æµè§ˆå’Œç®¡ç†Claude Codeå†å²å¯¹è¯
â€¢ æŸ¥çœ‹å®Œæ•´å¯¹è¯å†…å®¹
â€¢ æ™ºèƒ½æœç´¢å¯¹è¯å†…å®¹ï¼ˆå¹¶å‘æœç´¢ + ç¼“å­˜ + ç›¸å…³æ€§æ’åºï¼‰
â€¢ åˆ†é¡µæµè§ˆæ”¯æŒå¤§é‡å¯¹è¯ï¼ˆ20/50/100/200æ¡/é¡µï¼‰
â€¢ å¯¼å‡ºå¯¹è¯ä¸ºMarkdown/JSONæ ¼å¼
â€¢ å®‰å…¨åˆ é™¤å¯¹è¯
â€¢ å¤‡ä»½æ‰€æœ‰å¯¹è¯
â€¢ Tokenè®¡ç®—å’Œæˆæœ¬ä¼°ç®—
â€¢ å®æ—¶ç»Ÿè®¡æ˜¾ç¤ºé¢æ¿
â€¢ ä¸°å¯Œçš„é”®ç›˜å¿«æ·é”®æ”¯æŒ

UIä¼˜åŒ–ç‰¹æ€§:
â€¢ åˆ†é¡µæµè§ˆ - é«˜æ•ˆå¤„ç†å¤§é‡å¯¹è¯
â€¢ å®æ—¶ç»Ÿè®¡ - é¡¹ç›®æ•°æ®å®æ—¶æ˜¾ç¤º
â€¢ è¿›åº¦æŒ‡ç¤ºå™¨ - å¼‚æ­¥æ“ä½œè¿›åº¦åé¦ˆ
â€¢ é”®ç›˜å¯¼èˆª - å®Œæ•´çš„å¿«æ·é”®æ”¯æŒ
â€¢ ç„¦ç‚¹ç®¡ç† - æ™ºèƒ½ç„¦ç‚¹åˆ‡æ¢
â€¢ å“åº”å¼ç•Œé¢ - ä¼˜åŒ–ç”¨æˆ·ä½“éªŒ

é”®ç›˜å¿«æ·é”®:
â€¢ Ctrl+F - æœç´¢ | F5 - åˆ·æ–° | Ctrl+R - åˆ é™¤å¯¹è¯
â€¢ Ctrl+E - å¯¼å‡º | Esc - æ¸…é™¤æœç´¢
â€¢ æ–¹å‘é”® - å¯¼èˆªå¯¹è¯ | PageUp/Down - åˆ†é¡µ
â€¢ Home/End - é¦–é¡µ/æœ«é¡µ | Tab - åˆ‡æ¢é¢æ¿ç„¦ç‚¹

æ€§èƒ½ç»Ÿè®¡:
â€¢ Tokenç¼“å­˜å‘½ä¸­ç‡: {token_hit_rate:.1f}% ({token_hits}/{token_total})
â€¢ æœç´¢ç¼“å­˜å¤§å°: {search_cache_size} é¡¹
â€¢ æ–‡ä»¶åˆ†æç¼“å­˜: {file_cache_size} é¡¹
â€¢ è®¡ç®—å™¨æ¨¡å¼: {'ç²¾ç¡®æ¨¡å¼' if self.token_calculator.precise_mode else 'ä¼°ç®—æ¨¡å¼'}
â€¢ åˆ†é¡µå¤§å°: {self.page_size} æ¡/é¡µ

æŠ€æœ¯æ ˆ:
â€¢ Python + tkinter
â€¢ concurrent.futures å¹¶å‘å¤„ç†
â€¢ LRUç¼“å­˜ä¼˜åŒ–
â€¢ è·¨å¹³å°æ”¯æŒ
â€¢ å“åº”å¼UIè®¾è®¡

Â© 2025 All rights reserved."""

        messagebox.showinfo("å…³äº", about_text)

    def _update_pagination(self):
        """æ›´æ–°åˆ†é¡µçŠ¶æ€"""
        if not self.filtered_conversations:
            self.total_pages = 1
        else:
            self.total_pages = (len(self.filtered_conversations) + self.page_size - 1) // self.page_size

        # ç¡®ä¿å½“å‰é¡µåœ¨æœ‰æ•ˆèŒƒå›´å†…
        if self.current_page < 1:
            self.current_page = 1
        elif self.current_page > self.total_pages:
            self.current_page = self.total_pages

    def _update_pagination_info(self):
        """æ›´æ–°åˆ†é¡µä¿¡æ¯æ˜¾ç¤º"""
        if self.total_pages <= 1:
            page_text = f"å…± {len(self.filtered_conversations)} ä¸ªå¯¹è¯"
        else:
            start_idx = (self.current_page - 1) * self.page_size + 1
            end_idx = min(self.current_page * self.page_size, len(self.filtered_conversations))
            page_text = f"ç¬¬ {self.current_page} é¡µï¼Œå…± {self.total_pages} é¡µ | æ˜¾ç¤º {start_idx}-{end_idx} é¡¹ï¼Œå…± {len(self.filtered_conversations)} é¡¹"

        self.page_info_label.config(text=page_text)

        # æ›´æ–°æŒ‰é’®çŠ¶æ€
        self.first_page_btn.config(state=tk.NORMAL if self.current_page > 1 else tk.DISABLED)
        self.prev_page_btn.config(state=tk.NORMAL if self.current_page > 1 else tk.DISABLED)
        self.next_page_btn.config(state=tk.NORMAL if self.current_page < self.total_pages else tk.DISABLED)
        self.last_page_btn.config(state=tk.NORMAL if self.current_page < self.total_pages else tk.DISABLED)

        # æ›´æ–°é¡µç è¾“å…¥æ¡†
        self.page_var.set(str(self.current_page))

    def _go_to_first_page(self):
        """è·³è½¬åˆ°ç¬¬ä¸€é¡µ"""
        if self.current_page != 1:
            self.current_page = 1
            self._update_conversation_list()

    def _go_to_prev_page(self):
        """è·³è½¬åˆ°ä¸Šä¸€é¡µ"""
        if self.current_page > 1:
            self.current_page -= 1
            self._update_conversation_list()

    def _go_to_next_page(self):
        """è·³è½¬åˆ°ä¸‹ä¸€é¡µ"""
        if self.current_page < self.total_pages:
            self.current_page += 1
            self._update_conversation_list()

    def _go_to_last_page(self):
        """è·³è½¬åˆ°æœ€åä¸€é¡µ"""
        if self.current_page != self.total_pages:
            self.current_page = self.total_pages
            self._update_conversation_list()

    def _jump_to_page(self, event=None):
        """è·³è½¬åˆ°æŒ‡å®šé¡µ"""
        try:
            page_num = int(self.page_var.get())
            if 1 <= page_num <= self.total_pages:
                if self.current_page != page_num:
                    self.current_page = page_num
                    self._update_conversation_list()
            else:
                # æ¢å¤å½“å‰é¡µç 
                self.page_var.set(str(self.current_page))
                messagebox.showwarning("è­¦å‘Š", f"é¡µç å¿…é¡»åœ¨ 1-{self.total_pages} ä¹‹é—´")
        except ValueError:
            # æ¢å¤å½“å‰é¡µç 
            self.page_var.set(str(self.current_page))
            messagebox.showwarning("è­¦å‘Š", "è¯·è¾“å…¥æœ‰æ•ˆçš„é¡µç ")

    def _on_page_size_change(self, event=None):
        """é¡µç å¤§å°æ”¹å˜äº‹ä»¶"""
        try:
            new_page_size = int(self.page_size_var.get())
            if self.page_size != new_page_size:
                self.page_size = new_page_size
                self.current_page = 1  # é‡ç½®åˆ°ç¬¬ä¸€é¡µ
                self._update_pagination()
                self._update_conversation_list()
        except ValueError:
            # æ¢å¤åŸå§‹é¡µç å¤§å°
            self.page_size_var.set(str(self.page_size))

    def _show_progress(self, message: str = "æ­£åœ¨å¤„ç†..."):
        """æ˜¾ç¤ºè¿›åº¦æ¡"""
        self.progress_label.config(text=message)
        self.progress_bar.pack(side=tk.LEFT, padx=(0, 10))
        self.progress_label.pack(side=tk.LEFT)
        self.progress_var.set(0)
        self.root.update()

    def _update_progress(self, value: float, message: str = None):
        """æ›´æ–°è¿›åº¦æ¡"""
        self.progress_var.set(value)
        if message:
            self.progress_label.config(text=message)
        self.root.update()

    def _hide_progress(self):
        """éšè—è¿›åº¦æ¡"""
        self.progress_bar.pack_forget()
        self.progress_label.pack_forget()
        self.progress_var.set(0)
        self.root.update()

    def _setup_keyboard_shortcuts(self):
        """è®¾ç½®é”®ç›˜å¿«æ·é”®"""
        # Ctrl+F - æœç´¢
        self.root.bind('<Control-f>', lambda e: self._focus_search())
        self.root.bind('<Control-F>', lambda e: self._focus_search())

        # F5 - åˆ·æ–°
        self.root.bind('<F5>', lambda e: self._load_projects())

        # Ctrl+R - åˆ é™¤å¯¹è¯
        self.root.bind('<Control-r>', lambda e: self._delete_conversation())
        self.root.bind('<Control-R>', lambda e: self._delete_conversation())

        # Ctrl+E - å¯¼å‡ºå½“å‰å¯¹è¯
        self.root.bind('<Control-e>', lambda e: self._export_current_markdown())
        self.root.bind('<Control-E>', lambda e: self._export_current_markdown())

        # Escape - æ¸…é™¤æœç´¢
        self.root.bind('<Escape>', lambda e: self._clear_search())

        # æ–¹å‘é”® - å¯¼èˆªå¯¹è¯åˆ—è¡¨
        self.root.bind('<Up>', lambda e: self._navigate_conversation_list(-1))
        self.root.bind('<Down>', lambda e: self._navigate_conversation_list(1))

        # PageUp/PageDown - åˆ†é¡µå¯¼èˆª
        self.root.bind('<Prior>', lambda e: self._go_to_prev_page())  # PageUp
        self.root.bind('<Next>', lambda e: self._go_to_next_page())   # PageDown

        # Home/End - é¦–é¡µ/æœ«é¡µ
        self.root.bind('<Home>', lambda e: self._go_to_first_page())
        self.root.bind('<End>', lambda e: self._go_to_last_page())

        # Enter - æŸ¥çœ‹é€‰ä¸­çš„å¯¹è¯
        self.root.bind('<Return>', lambda e: self._view_conversation())

        # Tab - åœ¨é¢æ¿é—´åˆ‡æ¢ç„¦ç‚¹
        self.root.bind('<Control-Tab>', lambda e: self._switch_panel_focus())
        self.root.bind('<Control-Shift-Tab>', lambda e: self._switch_panel_focus(reverse=True))

        # Ctrl+1/2/3 - ç›´æ¥åˆ‡æ¢åˆ°é¡¹ç›®/æœç´¢/å¯¹è¯åˆ—è¡¨
        self.root.bind('<Control-1>', lambda e: self._focus_project_combo())
        self.root.bind('<Control-2>', lambda e: self._focus_search())
        self.root.bind('<Control-3>', lambda e: self._focus_conversation_list())

    def _focus_search(self):
        """èšç„¦åˆ°æœç´¢æ¡†"""
        self.search_entry.focus_set()
        self.search_entry.select_range(0, tk.END)

    def _focus_project_combo(self):
        """èšç„¦åˆ°é¡¹ç›®é€‰æ‹©æ¡†"""
        self.project_combo.focus_set()
        self.project_combo.open_dropdown()

    def _focus_conversation_list(self):
        """èšç„¦åˆ°å¯¹è¯åˆ—è¡¨"""
        self.conversation_tree.focus_set()
        if self.conversation_tree.get_children():
            self.conversation_tree.selection_set(self.conversation_tree.get_children()[0])

    def _navigate_conversation_list(self, direction: int):
        """åœ¨å¯¹è¯åˆ—è¡¨ä¸­å¯¼èˆª"""
        items = self.conversation_tree.get_children()
        if not items:
            return

        selected = self.conversation_tree.selection()
        if selected:
            current_index = items.index(selected[0])
        else:
            current_index = -1

        new_index = current_index + direction
        if 0 <= new_index < len(items):
            self.conversation_tree.selection_set(items[new_index])
            self.conversation_tree.see(items[new_index])
            self._view_conversation(show_warning=False)

    def _switch_panel_focus(self, reverse: bool = False):
        """åœ¨é¢æ¿é—´åˆ‡æ¢ç„¦ç‚¹"""
        widgets = [self.project_combo, self.search_entry, self.conversation_tree,
                  self.message_listbox, self.content_text]

        current_focus = self.root.focus_get()
        if current_focus in widgets:
            current_index = widgets.index(current_focus)
            if reverse:
                new_index = (current_index - 1) % len(widgets)
            else:
                new_index = (current_index + 1) % len(widgets)
            widgets[new_index].focus_set()

    def cleanup(self):
        """æ¸…ç†èµ„æºï¼Œé˜²æ­¢å†…å­˜æ³„æ¼"""
        if hasattr(self, '_sort_block_timer') and self._sort_block_timer:
            self.root.after_cancel(self._sort_block_timer)
            self._sort_block_timer = None

    def run(self):
        """è¿è¡Œåº”ç”¨"""
        try:
            self.root.mainloop()
        finally:
            self.cleanup()


def main():
    """ä¸»å‡½æ•°"""
    try:
        # æ£€æŸ¥Pythonç‰ˆæœ¬
        if sys.version_info < (3, 7):
            print("é”™è¯¯: éœ€è¦ Python 3.7 æˆ–æ›´é«˜ç‰ˆæœ¬")
            sys.exit(1)

        # æ£€æŸ¥tkinteræ˜¯å¦å¯ç”¨
        try:
            import tkinter as tk_test
        except ImportError:
            print("é”™è¯¯: tkinter æ¨¡å—ä¸å¯ç”¨ï¼Œè¯·å®‰è£… Python tkinter")
            sys.exit(1)

        # åˆ›å»ºå¹¶è¿è¡Œåº”ç”¨
        app = ClaudeHistoryGUI()
        app.run()

    except KeyboardInterrupt:
        print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        error_msg = f"åº”ç”¨å¯åŠ¨å¤±è´¥: {e}"
        try:
            # å¦‚æœGUIå·²ç»åˆå§‹åŒ–ï¼Œæ˜¾ç¤ºé”™è¯¯å¯¹è¯æ¡†
            messagebox.showerror("å¯åŠ¨é”™è¯¯", error_msg)
        except:
            # GUIæœªåˆå§‹åŒ–ï¼Œæ‰“å°åˆ°æ§åˆ¶å°
            print(error_msg)
        sys.exit(1)


if __name__ == '__main__':
    main()